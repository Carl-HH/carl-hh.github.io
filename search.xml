<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Condition接口]]></title>
    <url>%2F2018%2F09%2F30%2Fconcurrent%2FCondition%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[Condition接口示例 ​ Condition是在AQS中配合使用的wait/nofity线程通信协调工具类，我们可以称之为等待队列。​ Condition定义了等待/通知两种类型的方法，当前线程调用这些方法时，需要提前获取到Condition对象关联的锁。Condition对象是调用Lock对象的newCondition()方法创建出来的，换句话说，Condition是依赖Lock对象的。 123456789101112131415161718192021&gt; Lock lock = new ReentrantLock();&gt; Condition condition = lock.newCondition();&gt; &gt; public void conditonWait() throws InterruptedException &#123;&gt; lock.lock();&gt; try &#123;&gt; condition.wait();&gt; &#125; finally &#123;&gt; lock.unlock();&gt; &#125;&gt; &#125;&gt; &gt; public void conditonSignal() throws InterruptedException &#123;&gt; lock.lock();&gt; try &#123;&gt; condition.signal();&gt; &#125; finally &#123;&gt; lock.unlock();&gt; &#125;&gt; &#125;&gt; 代码如上，Condition 对象作为成员变量，当调用await()方法后，当前线程会释放锁并在此等待，而其他线程调用Conditon对象的signal() 方法，通知当前线程后，当前线程才从await()方法返回，并且在返回前已经获取了锁。 ​ condition定义的（部分）方法以及描述： 获取一个Condition必须通过Lock的newCondition()方法。下面通过一个有界队列的示例来深入了解Condition的使用方式。 1234567891011121314151617181920212223242526272829303132333435363738394041&gt; public class BoundedQueue&lt;T&gt; &#123;&gt; &gt; private LinkedList&lt;Object&gt; items;&gt; private int size;&gt; private Lock lock = new ReentrantLock(); //删除线程进等待队列&gt; private Condition notEmpty = lock.newCondition(); //增加元素等待队列&gt; private Condition notFull = lock.newCondition();&gt; &gt; public BoundedQueue(int size) &#123;&gt; this.size = size;&gt; items = new LinkedList&lt;&gt;();&gt; &#125;&gt; &gt; // 添加一个元素，如果数组满，则添加线程进入等待状态，直到有"空位"&gt; public void add(T t) throws InterruptedException &#123;&gt; lock.lock();&gt; try &#123;&gt; while (size == items.size())&gt; notFull.await(); //数组未满&gt; items.add(t); //删除线程的等待队列唤醒&gt; notEmpty.signal();&gt; &#125; finally &#123;&gt; lock.unlock();&gt; &#125;&gt; &#125;&gt; &gt; // 由头部删除一个元素，如果数组空，则删除线程进入等待状态，直到有新添加元素&gt; public T remove() throws InterruptedException &#123;&gt; lock.lock();&gt; try &#123;&gt; while (items.size() == 0)&gt; notEmpty.await();&gt; Object x = items.poll();&gt; notFull.signal();&gt; return (T) x;&gt; &#125; finally &#123;&gt; lock.unlock();&gt; &#125;&gt; &#125;&gt; &#125;&gt; ​ 上述示例中，BoundedQueue通过add(T t)方法添加一个元素，通过remove()方法移出一个元素。​ 以添加方法为例:首先需要获得锁，目的是确保数组修改的可见性和排他性。当数组数量等于数组长度时，表示数组已满，则调用notFull.await()，当前线程随之释放锁并进入等待状态。如果数组数量不等于数组长度，表示数组未满，则添加元素到数组中，同时通知等待在notEmpty上的线程，数组中已经有新元素可以获取。​ 在加和删除方法中使用while循环而非if判断，目的是防止过早或意外的通知，只有条件符合才能够退出循环。 实现分析等待队列 ​ 等待队列是一个FIFO的队列，在队列中的每个节点都包含了一个线程引用，该线程就是在Condition对象上等待的线程，如果一个线程调用了Condition.await()方法，那么该线程将会释放锁、构造成节点加入等待队列并进入等待状态。事实上，节点的定义复用了同步器中节点的定义，也就是说，同步队列和等待队列中节点类型都是同步器的静态内部类AbstractQueuedSynchronizer.Node。​ 一个Condition包含一个等待队列，Condition拥有首节点（ firstWaiter ）和尾节点（ lastWaiter ）。当前线程调用Condition.await()方法，将会以当前线程构造节点，并将节点从尾部加入等待队列，等待队列的基本结构如下所示：​ ​ 如图所示，Condition拥有首尾节点的引用，而新增节点只需要将原有的尾节点nextWaiter指向它，并且更新尾节点即可。上述节点引用更新的过程并没有使用CAS保证，原因在于调用await()方法的线程必定是获取了锁的线程，也就是说该过程是由锁来保证线程安全的。​ 在Object的监视器模型上，一个对象拥有一个同步队列和等待队列，而并发包中的Lock实现类拥有一个同步队列和多个等待队列。​ ​ 如上图所示，Condition的实现是同步器的内部类，因此每个Condition实例都能够访问同步器提供的方法，相当于每个Condition都拥有所属同步器的引用。 等待 ​ 调用Condition的await()方法（或者以await开头的方法），会使当前线程进入等待队列并释放锁，同时线程状态变为等待状态。当从await()方法返回时，当前线程一定获取了Condition相关联的锁。​ 如果从队列（同步队列和等待队列）的角度看await()方法，当调用await()方法时，相当于同步队列的首节点（获取了锁的节点）移动到Condition的等待队列中。 Condition的await()方法 12345678910111213141516171819&gt; public final void await() throws InterruptedException &#123;&gt; if (Thread.interrupted())&gt; throw new InterruptedException();&gt; Node node = addConditionWaiter();&gt; int savedState = fullyRelease(node);&gt; int interruptMode = 0;&gt; while (!isOnSyncQueue(node)) &#123;&gt; LockSupport.park(this);&gt; if ((interruptMode = checkInterruptWhileWaiting(node)) != 0)&gt; break;&gt; &#125;&gt; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE)&gt; interruptMode = REINTERRUPT;&gt; if (node.nextWaiter != null) // clean up if cancelled&gt; unlinkCancelledWaiters();&gt; if (interruptMode != 0)&gt; reportInterruptAfterWait(interruptMode);&gt; &#125;&gt; ​ 调用该方法的线程成功获取了锁的线程，也就是同步队列中的首节点，该方法会将当前线程构造成节点并加入等待队列中，（ 因为已经获取了同步状态，所以无需通过cas,在队列尾部添加等待节点 ）然后释放同步状态，唤醒同步队列中的后继节点，然后当前线程会进入等待状态。​ 当等待队列中的节点被唤醒，则唤醒节点的线程开始尝试获取同步状态。如果不是通过其他线程调用Condition.signal()方法唤醒，而是对等待线程进行中断，则会抛出InterruptedException。​ 如果从队列的角度去看，当前线程加入Condition的等待队列，如图所示，同步队列的首节点并不会直接加入等待队列，而是通过addConditionWaiter()方法把当前线程构造成一个新的节点并将其加入等待队列中。​ 通知 ​ 调用Condition的signal()方法，将会唤醒在等待队列中等待时间最长的节点（首节点），在唤醒节点之前，会将节点移到同步队列末尾。 1234567891011121314151617181920212223242526272829303132333435&gt; public final void signal() &#123;&gt; if (!isHeldExclusively())&gt; throw new IllegalMonitorStateException();&gt; Node first = firstWaiter;&gt; if (first != null)&gt; doSignal(first);&gt; &#125;&gt; private void doSignal(Node first) &#123;&gt; do &#123;&gt; if ( (firstWaiter = first.nextWaiter) == null)&gt; lastWaiter = null;&gt; first.nextWaiter = null;&gt; &#125; while (!transferForSignal(first) &amp;&amp;&gt; (first = firstWaiter) != null);&gt; &#125;&gt; final boolean transferForSignal(Node node) &#123;&gt; /*&gt; * If cannot change waitStatus, the node has been cancelled.&gt; */&gt; if (!compareAndSetWaitStatus(node, Node.CONDITION, 0))&gt; return false;&gt; &gt; /*&gt; * Splice onto queue and try to set waitStatus of predecessor to&gt; * indicate that thread is (probably) waiting. If cancelled or&gt; * attempt to set waitStatus fails, wake up to resync (in which&gt; * case the waitStatus can be transiently and harmlessly wrong).&gt; */&gt; Node p = enq(node);&gt; int ws = p.waitStatus;&gt; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL))&gt; LockSupport.unpark(node.thread);&gt; return true;&gt; &#125;&gt; ​ 调用signal方法的前置条件是当前线程必须获取了锁，可以看到signal()方法进行了isHeldExclusively()检查，也就是当前线程必须是获取了锁的线程。接着获取等待队列的首节点，将其移动到同步队列并使用LockSupport唤醒节点中的线程。​ 节点从等待队列移动到同步队列的过程如下图所示： 通过调用同步器的enq(Node node)方法，等待队列中的头节点线程安全地移动到同步队列。 当节点移动到同步队列后，当前线程再使用LockSupport唤醒该节点的线程。 被唤醒后的线程，将从await()方法中的while循环中退出（isOnSyncQueue(Node node)方法返回true，节点已经在同步队列中），进而调用同步器的acquireQueued()方法加入到获取同步状态的竞争中。 成功获取同步状态之后，被唤醒的线程将从先前调用的await()方法返回，此时该线程已经成功地获取了锁。 Condition的sihnalAll()方法，相当于对等待队列中的每个节点都执行一次signal()方法，效果就是将等待队列中的所有节点全部移动到同步队列中，并唤醒每个节点的线程。代码如下： 1234567891011121314151617&gt; public final void signalAll() &#123;&gt; if (!isHeldExclusively())&gt; throw new IllegalMonitorStateException();&gt; Node first = firstWaiter;&gt; if (first != null)&gt; doSignalAll(first);&gt; &#125;&gt; private void doSignalAll(Node first) &#123;&gt; lastWaiter = firstWaiter = null;&gt; do &#123;&gt; Node next = first.nextWaiter;&gt; first.nextWaiter = null;&gt; transferForSignal(first);&gt; first = next;&gt; &#125; while (first != null);&gt; &#125;&gt;]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[读写锁]]></title>
    <url>%2F2018%2F09%2F30%2Fconcurrent%2F%E8%AF%BB%E5%86%99%E9%94%81%2F</url>
    <content type="text"><![CDATA[​ 排他锁在同一时刻只允许一个线程进行访问，而读写锁在统一时刻允许多个读线程访问，但是在写线程访问时，所有的读写线程都被阻塞。读写锁维护了一对锁，一个读锁，一个写锁，通过分离读锁和写锁，使得并发性相比一般的排他锁有很大提升。因为大多数应用场景都是读多于写的，因此在这样的情况下，读写锁可以提高吞吐量。​ 读写锁三大特性：公平性选择、重进入、锁降级 特性 说明 公平性选择 支持非公平（默认）和公平的锁获取方式，吞吐量还是非公平性由于公平 重进入 该锁支持重入，以读写线程为例：读线程在获取读锁之后，能够再次获取读锁。而写线程在获取了写锁之后，能够再次获取写锁，同时也可以获取读锁 锁降级 遵循获取写锁、获取读锁在释放写锁的次序，写锁可以降级为读锁 读写锁的实现分析读写状态的设计 ​ 读写锁同样利用同步器实现锁的功能，在ReetrantLock中，同步状态表示锁被一个线程重复获取的次数，而读写锁的自定义同步器需要在同步状态上维护多个读线程和一个写线程的状态。如果想在一个整型变量上维护这样一个状态，那么采用按位分割的方式是一个不错的选择。如下图所示，将一个变量分为两个部分，高16位表示读，低16位表示写 ​ 上图中同步状态表示一个线程已经获取了写锁，且重进入了两次，同时也连续获取了两次读锁。想要快速读取这个状态，可以通过位运算。当前状态为S，写状态等于S&amp;0x0000FFFF，读状态等S&gt;&gt;&gt;16。当读状态+1时，等于S+1，写状态加1等于S+（1&lt;&lt;16）。 写锁的获取与释放 ​ 写锁是一个支持重进入的排它锁。如果当前线程获取了写锁，则增加写状态。如果当前线程在获取写锁时，读锁已经获取（读状态不为0）或者该线程不是已经获取写锁的线程，则当前线程进入等待状态。 123456789101112131415161718192021222324252627282930313233&gt; protected final boolean tryAcquire(int acquires) &#123;&gt; /*&gt; * Walkthrough:&gt; * 1. If read count nonzero or write count nonzero&gt; * and owner is a different thread, fail.&gt; * 2. If count would saturate, fail. (This can only&gt; * happen if count is already nonzero.)&gt; * 3. Otherwise, this thread is eligible for lock if&gt; * it is either a reentrant acquire or&gt; * queue policy allows it. If so, update state&gt; * and set owner.&gt; */&gt; Thread current = Thread.currentThread();&gt; int c = getState();&gt; int w = exclusiveCount(c);&gt; if (c != 0) &#123;&gt; // (Note: if c != 0 and w == 0 then shared count != 0)&gt; //如果存在读锁 或者当前线程不是获取写锁的线程 返回false&gt; if (w == 0 || current != getExclusiveOwnerThread())&gt; return false;&gt; if (w + exclusiveCount(acquires) &gt; MAX_COUNT)&gt; throw new Error("Maximum lock count exceeded");&gt; // Reentrant acquire&gt; setState(c + acquires);&gt; return true;&gt; &#125;&gt; if (writerShouldBlock() ||&gt; !compareAndSetState(c, c + acquires))&gt; return false;&gt; setExclusiveOwnerThread(current);&gt; return true;&gt; &#125;&gt; ​ 该方法处理重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：读写锁要确保写锁的操作对读锁是可见的。如果允许读锁在已被获取的情况下对写锁获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。因此，只有等待其他线程都释放了读锁，写锁才能被当前线程获取，写锁一旦被获取，则其他读写线程的后续访问都被阻塞。​ 写锁的释放和ReentrantLock的释放过程基本类似，每次释放减少写状态，当写状态为0时表示写锁已被释放，从而等待的读写线程能够继续访问读写锁，同时前次写线程的修改对后续读写线程可见。 读锁的获取与释放 ​ 读锁是一个支持重进入的共享锁，它能够被多个线程同时获取，在没有其他线程访问时，读锁总会被成功地获取。如果当前线程已经获取了读锁，则增加读状态，如果获取读锁时写锁已经被其他线程获取，则进入等待状态。 12345678910111213141516171819202122232425262728293031323334353637383940414243&gt; protected final int tryAcquireShared(int unused) &#123;&gt; /*&gt; * Walkthrough:&gt; * 1. If write lock held by another thread, fail.&gt; * 2. Otherwise, this thread is eligible for&gt; * lock wrt state, so ask if it should block&gt; * because of queue policy. If not, try&gt; * to grant by CASing state and updating count.&gt; * Note that step does not check for reentrant&gt; * acquires, which is postponed to full version&gt; * to avoid having to check hold count in&gt; * the more typical non-reentrant case.&gt; * 3. If step 2 fails either because thread&gt; * apparently not eligible or CAS fails or count&gt; * saturated, chain to version with full retry loop.&gt; */&gt; Thread current = Thread.currentThread();&gt; int c = getState();&gt; if (exclusiveCount(c) != 0 &amp;&amp;&gt; getExclusiveOwnerThread() != current)&gt; return -1;&gt; int r = sharedCount(c);&gt; if (!readerShouldBlock() &amp;&amp;&gt; r &lt; MAX_COUNT &amp;&amp;&gt; compareAndSetState(c, c + SHARED_UNIT)) &#123;&gt; if (r == 0) &#123;&gt; firstReader = current;&gt; firstReaderHoldCount = 1;&gt; &#125; else if (firstReader == current) &#123;&gt; firstReaderHoldCount++;&gt; &#125; else &#123;&gt; HoldCounter rh = cachedHoldCounter;&gt; if (rh == null || rh.tid != getThreadId(current))&gt; cachedHoldCounter = rh = readHolds.get();&gt; else if (rh.count == 0)&gt; readHolds.set(rh);&gt; rh.count++;&gt; &#125;&gt; return 1;&gt; &#125;&gt; return fullTryAcquireShared(current);&gt; &#125;&gt; ​ 在该方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加状态，成功获取读锁。如果当前线程满足对state的操作条件，就利用CAS设置state+SHARED_UNIT,实际上就是读状态+1。但是需要注意，这个state是全局的，即所有线程获取读锁次数的总和，而为了方便计算本线程的读锁次数以及释放掉锁，需要在ThreadLocal中维护一个变量。这就是HoldCounter。源码下半部分的基本做的事情就是在让HoldCounter加一。​ 读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是（1 &lt;&lt; 16）。 锁降级 锁降级是指写锁降级为读锁，如果当前线程拥有写锁，然后将其释放，最后再获取读锁，这种分段完成的过程不能称之为锁降级。锁降级是指把持住（当前拥有的）写锁，在获取读锁，随后释放（先前拥有的）写锁的过程。 123456789101112131415161718192021222324252627&gt; public class ProcessData &#123;&gt; private static final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();&gt; private static final Lock readLock = rwl.readLock();&gt; private static final Lock writeLock = rwl.writeLock();&gt; private volatile boolean update = false;&gt; &gt; public void processData() &#123;&gt; readLock.lock();&gt; if (!update) &#123;&gt; readLock.unlock();&gt; writeLock.lock();&gt; try &#123;&gt; if (!update) &#123;&gt; update = true;&gt; &#125;&gt; readLock.lock();&gt; &#125; finally &#123;&gt; writeLock.unlock();&gt; &#125;&gt; &#125;&gt; try &#123;&gt; &#125; finally &#123;&gt; readLock.unlock();&gt; &#125;&gt; &#125;&gt; &#125;&gt; ​ 以上例子说明了一个锁降级的过程。当数据发生变化时，update变量被设置为false，此时所有访问process（）方法的线程都能够感知到变化，但只有一个线程可以获取到写锁，其他线程会被阻塞在读锁和写锁的Lock（）方法上。当前线程获取写锁完成数据准备之后，在获取读锁，随后释放写锁，完成锁降级。​ 锁降级主要是保证数据可见性，如果当前线程不先获取读锁而直接释放写锁，若此时有另外一个线程T获取了写锁并修改了数据，那么当前线程无法感知线程T的数据更新。如果当前线程获取读锁，则线程T将会被阻塞，直到当前线程使用数据并释放读锁之后，线程T才能获取写锁进行数据更新。]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[重入锁]]></title>
    <url>%2F2018%2F09%2F30%2Fconcurrent%2F%E9%87%8D%E5%85%A5%E9%94%81%2F</url>
    <content type="text"><![CDATA[​ ReentrantLock 是一种支持支持重进入的锁，它表示该锁能够支持一个线程对资源的重复加锁，除此之外，该锁还支持获取锁的公平性和非公平性选择。 实现重进入 重进入是指任意线程在获取到锁之后能够再次获取该锁而不会被阻塞，该特性实现需要解决以下两个问题 线程再次获取锁。锁需要去识别获取锁的线程是否为当前占据锁的线程，如果是，则再次获取成功。 锁最终的释放。线程重复获取锁n次，随后在第n次释放锁后，其他线程能够获取到该锁。锁的最终释放要求锁对于获取进行计数自增，计数表示当前锁被重复获取的次数，而锁被释放的时候，计数自减，当计数为0时，表示锁以及成功释放。 ReentrantLock 是通过组合自定义同步器来实现锁的获取和释放的，以非公平锁为例，获取同步状态的代码如下： 12345678910111213141516171819&gt;final boolean nonfairTryAcquire(int acquires) &#123;&gt; final Thread current = Thread.currentThread();&gt; int c = getState();&gt; if (c == 0) &#123;&gt; if (compareAndSetState(0, acquires)) &#123;&gt; setExclusiveOwnerThread(current);&gt; return true;&gt; &#125;&gt; &#125;&gt; else if (current == getExclusiveOwnerThread()) &#123;&gt; int nextc = c + acquires;&gt; if (nextc &lt; 0) // overflow&gt; throw new Error("Maximum lock count exceeded");&gt; setState(nextc);&gt; return true;&gt; &#125;&gt; return false;&gt; &#125;&gt; ​ 该方法增加了再次获取同步状态的逻辑，通过判断当前线程是否为获取锁的线程来决定获取操作是否成功，如果是获取锁的线程再次请求，则将同步状态值进行增加并返回true，表示获取同步状态成功。​ 成功获取锁的线程再次获取锁，只是增加了同步状态的值。而ReentrantLock 在释放锁的时候，也是减少同步状态的值，代码如下： 12345678910111213&gt;protected final boolean tryRelease(int releases) &#123;&gt; int c = getState() - releases;&gt; if (Thread.currentThread() != getExclusiveOwnerThread())&gt; throw new IllegalMonitorStateException();&gt; boolean free = false;&gt; if (c == 0) &#123;&gt; free = true;&gt; setExclusiveOwnerThread(null);&gt; &#125;&gt; setState(c);&gt; return free;&gt; &#125;&gt; 公平锁与非公平锁的区别 ​ 公平锁还是非公平锁，取决于锁获取的顺序请求的绝对时间顺序，也就是FIFO。对于非公平锁，只要CAS设置同步状态成功，则表示当前线程获取了锁，而公平锁则不同，代码如下 1234567891011121314151617181920212223242526272829303132&gt;protected final boolean tryAcquire(int acquires) &#123;&gt; final Thread current = Thread.currentThread();&gt; int c = getState();&gt; if (c == 0) &#123;&gt; if (!hasQueuedPredecessors() &amp;&amp;&gt; compareAndSetState(0, acquires)) &#123;&gt; setExclusiveOwnerThread(current);&gt; return true;&gt; &#125;&gt; &#125;&gt; else if (current == getExclusiveOwnerThread()) &#123;&gt; int nextc = c + acquires;&gt; if (nextc &lt; 0)&gt; throw new Error("Maximum lock count exceeded");&gt; setState(nextc);&gt; return true;&gt; &#125;&gt; return false;&gt; &#125;&gt; &#125;&gt;&gt; public final boolean hasQueuedPredecessors() &#123;&gt; // The correctness of this depends on head being initialized&gt; // before tail and on head.next being accurate if the current&gt; // thread is first in queue.&gt; Node t = tail; // Read fields in reverse initialization order&gt; Node h = head;&gt; Node s;&gt; return h != t &amp;&amp;&gt; ((s = h.next) == null || s.thread != Thread.currentThread());&gt; &#125;&gt; ​ 与非公平锁获取锁不同，多了一个hasQueuedPredecessors 的方法，即加入了同步队列中当前节点是否有前驱节点的判断，如果有，表示有线程比当前线程更早地请求获取锁，因此需要等待前驱线程获取并释放锁后才能继续获取锁。​ 公平性锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[CPU多级缓存]]></title>
    <url>%2F2018%2F09%2F30%2Fconcurrent%2FCPU%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[CPU多级缓存cache因为CPU的频率太快了，快到主存跟不上，这样在处理器时钟周期内，CPU常常需要等待主存，浪费资源。所以cache的出现，是为了缓解CPU和内存之间速度的不匹配问题（结构：cpu -&gt; cache -&gt; memory）。出现的意义（局部性原理）： A. 时间局部性：如果某个数据被访问，那么在不久的将来它很可能被再次访问； B. 空间局部性：如果某个数据被访问，那么与它相邻的数据很快也可能被访问；MESI（缓存一致性）cache line: cache line是cache与内存数据交换的最小单位，根据操作系统一般是32byte或64byte。在MESI协议中，状态可以是M、E、S、I，地址则是cache line中映射的内存地址，数据则是从内存中读取的数据。| 状态 | 地址 | 数据 || ——– | —–: | :—-: || modified |0x00223000 | 5 | MESI协议中的状态 CPU中每个缓存行（caceh line)使用4种状态进行标记（使用额外的两位(bit)表示): M: 被修改（Modified) 该缓存行只被缓存在该CPU的缓存中，并且是被修改过的（dirty),即与主存中的数据不一致，该缓存行中的内存需要在未来的某个时间点（允许其它CPU读取请主存中相应内存之前）写回（write back）主存。当被写回主存之后，该缓存行的状态会变成独享（exclusive)状态。 E: 独享的（Exclusive) 该缓存行只被缓存在该CPU的缓存中，它是未被修改过的（clean)，与主存中数据一致。该状态可以在任何时刻当有其它CPU读取该内存时变成共享状态（shared)。同样地，当CPU修改该缓存行中内容时，该状态可以变成Modified状态。 S: 共享的（Shared) 该状态意味着该缓存行可能被多个CPU缓存，并且各个缓存中的数据与主存数据一致（clean)，当有一个CPU修改该缓存行中，其它CPU中该缓存行可以被作废（变成无效状态（Invalid））。 I: 无效的（Invalid） 该缓存是无效的（可能有其它CPU修改了该缓存行）。 MESI状态转换图状态之间的相互转换关系也可以使用下表进行表示。 说明：在一个典型系统中，可能会有几个缓存（在多核系统中，每个核心都会有自己的缓存）共享主存总线，每个相应的CPU会发出读写请求，而缓存的目的是为了减少CPU读写共享主存的次数。一个缓存除在Invalid状态外都可以满足cpu的读请求，一个invalid的缓存行必须从主存中读取（变成S或者 E状态）来满足该CPU的读请求。一个写请求只有在该缓存行是M或者E状态时才能被执行，如果缓存行处于S状态，必须先将其它缓存中该缓存行变成Invalid状态（也既是不允许不同CPU同时修改同一缓存行，即使修改该缓存行中不同位置的数据也不允许）。该操作经常作用广播的方式来完成，例如：Request For Ownership (RFO)缓存可以随时将一个非M状态的缓存行作废，或者变成Invalid状态，而一个M状态的缓存行必须先被写回主存。一个处于M状态的缓存行必须时刻监听所有试图读该缓存行相对就主存的操作，这种操作必须在缓存将该缓存行写回主存并将状态变成S状态之前被延迟执行。一个处于S状态的缓存行也必须监听其它缓存使该缓存行无效或者独享该缓存行的请求，并将该缓存行变成无效（Invalid）。一个处于E状态的缓存行也必须监听其它缓存读主存中该缓存行的操作，一旦有这种操作，该缓存行需要变成S状态。对于M和E状态而言总是精确的，他们在和该缓存行的真正状态是一致的。而S状态可能是非一致的，如果一个缓存将处于S状态的缓存行作废了，而另一个缓存实际上可能已经独享了该缓存行，但是该缓存却不会将该缓存行升迁为E状态，这是因为其它缓存不会广播他们作废掉该缓存行的通知，同样由于缓存并没有保存该缓存行的copy的数量，因此（即使有这种通知）也没有办法确定自己是否已经独享了该缓存行。从上面的意义看来E状态是一种投机性的优化：如果一个CPU想修改一个处于S状态的缓存行，总线事务需要将所有该缓存行的copy变成invalid状态，而修改E状态的缓存不需要使用总线事务。 乱序执行优化 CPU为提高运算速度而做出违背代码原有顺序的优化]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JUC常用组件]]></title>
    <url>%2F2018%2F09%2F28%2Fconcurrent%2FJUC%E5%B8%B8%E7%94%A8%E7%BB%84%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[AbstractQueuedSynchronizer CountDownLatch CountDownLatch的用法 某一线程在开始运行前等待n个线程执行完毕。将CountDownLatch的计数器初始化为n new CountDownLatch(n) ，每当一个任务线程执行完毕，就将计数器减1 countdownlatch.countDown()，当计数器的值变为0时，在CountDownLatch上 await() 的线程就会被唤醒。一个典型应用场景就是启动一个服务时，主线程需要等待多个组件加载完毕，之后再继续执行。 实现多个线程开始执行任务的最大并行性。注意是并行性，不是并发，强调的是多个线程在某一时刻同时开始执行。类似于赛跑，将多个线程放到起点，等待发令枪响，然后同时开跑。做法是初始化一个共享的CountDownLatch(1)，将其计数器初始化为1，多个线程在开始执行任务前首先 coundownlatch.await()，当主线程调用 countDown() 时，计数器变为0，多个线程同时被唤醒。 CountDownLatch的不足 CountDownLatch是一次性的，计数器的值只能在构造方法中初始化一次，之后没有任何机制再次对其设置值，当CountDownLatch使用完毕后，它不能再次被使用。 code1234567891011121314151617181920212223242526272829303132//示例：public class CountDownLatchEx1 &#123; private static final int THREADCOUNT = 200; public static void main(String[] args) throws Exception&#123; ExecutorService service = Executors.newCachedThreadPool(); final CountDownLatch countDownLatch = new CountDownLatch(THREADCOUNT); for (int i = 0; i &lt; THREADCOUNT; i++) &#123; final int threadNum = i; service.execute(() -&gt; &#123; try &#123; test(threadNum); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; countDownLatch.countDown(); &#125; &#125;); &#125; countDownLatch.await(); System.out.println("task finished"); service.shutdown(); &#125; private static void test(int threadNum) &#123; System.out.println("thread num:" + threadNum); &#125;&#125; 下面的例子指定等待时间：等待线程执行结束，到时间后，不再继续等待，若线程已经启动，会继续等待线程执行完毕后再销毁线程。 code 12345678910111213141516171819202122232425262728293031//指定等待时间public class CountDownLatchEx1 &#123; private static final int THREADCOUNT = 200; public static void main(String[] args) throws Exception&#123; ExecutorService service = Executors.newCachedThreadPool(); final CountDownLatch countDownLatch = new CountDownLatch(THREADCOUNT); for (int i = 0; i &lt; THREADCOUNT; i++) &#123; final int threadNum = i; service.execute(() -&gt; &#123; try &#123; test(threadNum); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; countDownLatch.countDown(); &#125; &#125;); &#125; countDownLatch.await(10, TimeUnit.MILLISECONDS); System.out.println("task finished"); service.shutdown(); &#125; private static void test(int threadNum) throws Exception &#123; Thread.sleep(30); System.out.println("thread num:" + threadNum); &#125; Semaphore ​ Semaphore是信号量，用于管理一组资源。其内部是基于AQS的共享模式，AQS的状态表示许可证的数量，在许可证数量不够时，线程将会被挂起；而一旦有一个线程释放一个资源，那么就有可能重新唤醒等待队列中的线程继续执行。123456789101112131415161718192021public static void main(String[] args) throws Exception&#123; ExecutorService service = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(3); for (int i = 0; i &lt; THREADCOUNT; i++) &#123; final int threadNum = i; service.execute(() -&gt; &#123; try &#123; semaphore.acquire(); test(threadNum); semaphore.release(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; &#125; &#125;); &#125; service.shutdown(); &#125; 可以通过tryAcquire方法设置超时时间，12345678910111213141516171819202122public static void main(String[] args) throws Exception&#123; ExecutorService service = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(3); for (int i = 0; i &lt; THREADCOUNT; i++) &#123; final int threadNum = i; service.execute(() -&gt; &#123; try &#123; if(semaphore.tryAcquire()) &#123; test(threadNum); semaphore.release(); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; &#125; &#125;); &#125; service.shutdown();&#125; CyclicBarrier ​ 可以理解为循环栅栏,栅栏就是一种障碍物.假如我们将计数器设置为10,那么凑齐第一批10个线程后,计数器就会归零,然后接着凑齐下一批10个线程,这就是循环栅栏的含义.构造器:12345678910111213141516171819202122232425262728293031public class CyclicBarrierEx1 &#123; private static CyclicBarrier cyclicBarrier = new CyclicBarrier(5); public static void main(String[] args) throws Exception &#123; ExecutorService executor = Executors.newCachedThreadPool(); for(int i = 0; i &lt; 10; i++) &#123; final int threadNum = i; Thread.sleep(1000); executor.execute(() -&gt; &#123; try &#123; test(threadNum); &#125; catch (Exception ex) &#123; ex.printStackTrace(); &#125; finally &#123; &#125; &#125;); &#125; executor.shutdown(); &#125; private static void test(int threadNum) throws Exception &#123; Thread.sleep(1000); System.out.println(threadNum + ": is ready"); cyclicBarrier.await(); System.out.println(threadNum + " continue"); &#125;&#125; ReentrantLock 重入锁：支持重进入的锁，表示该锁可以支持一个线程对资源的重复加锁。此外，还支持获取锁时的公平和非公平性选择。 123456789101112131415161718192021222324252627282930313233343536373839404142/*** ReentrantLock**/public class ReentrantLockEx1 &#123; public static int CLIENT_TOTAL = 5000; public static int THREAD_TOTAL = 200; public static int count = 0; public final static Lock lock = new ReentrantLock(); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(THREAD_TOTAL); final CountDownLatch countDownLatch = new CountDownLatch(CLIENT_TOTAL); for (int i = 0; i &lt; CLIENT_TOTAL; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println("count : " + count); &#125; private static void add() &#123; lock.lock(); try &#123; count++; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; ReentrantReadWriteLock 读写锁： 同一时刻可以允许多个读线程访问，但是在写线程访问时，所有读线程和写线程都被阻塞。读写锁维护了一对锁，一个读锁，一个写锁。 12345678910111213141516171819202122232425262728293031/*** ReentrantReadWriteLock**/public class ReentrantReadWriteLockEx1 &#123; private final Map&lt;String,Data&gt; map = new TreeMap&lt;&gt;(); //悲观锁 private final ReentrantReadWriteLock lock = new ReentrantReadWriteLock(); private final Lock readLock = lock.readLock(); private final Lock writeLock = lock.writeLock(); public Set&lt;String&gt; getAllKeys() &#123; readLock.lock(); try &#123; return map.keySet(); &#125; finally &#123; readLock.unlock(); &#125; &#125; public Data setKeys(String key,Data value) &#123; writeLock.lock(); try &#123; return map.put(key, value); &#125; finally &#123; writeLock.unlock(); &#125; &#125; class Data&#123;&#125;&#125; StampedLock 可以认为它是读写锁的一个改进版本，读写锁虽然分离了读和写的功能，使得读与读之间可以完全并发，但是读和写之间依然是冲突的，读锁会完全阻塞写锁，它使用的依然是悲观的锁策略，如果有大量的读线程，他也有可能引起写线程的饥饿，而StampedLock则提供了一种乐观的读策略，这种乐观策略的锁非常类似于无锁的操作，使得乐观锁完全不会阻塞写线程 123456789101112131415161718192021222324252627/*** StampedLock**/public class StampedLockEx1 &#123; private final Map&lt;String,Data&gt; map = new TreeMap&lt;&gt;(); private final StampedLock lock = new StampedLock(); public Set&lt;String&gt; getAllKeys() &#123; long stamp = lock.readLock(); try &#123; return map.keySet(); &#125; finally &#123; lock.unlock(stamp); &#125; &#125; public Data setKeys(String key,Data value) &#123; long stamp = lock.writeLock(); try &#123; return map.put(key, value); &#125; finally &#123; lock.unlock(stamp); &#125; &#125; class Data&#123;&#125;&#125; BoundedBuffer12345678910111213141516171819202122232425262728293031323334353637class BoundedBuffer &#123; final Lock lock = new ReentrantLock(); final Condition notFull = lock.newCondition(); final Condition notEmpty = lock.newCondition(); final Object[] items = new Object[100]; int putptr, takeptr, count; public void put(Object x) throws InterruptedException &#123; lock.lock(); try &#123; while (count == items.length) notFull.await(); items[putptr] = x; if (++putptr == items.length) putptr = 0; ++count; notEmpty.signal(); &#125; finally &#123; lock.unlock(); &#125; &#125; public Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (count == 0) notEmpty.await(); Object x = items[takeptr]; if (++takeptr == items.length) takeptr = 0; --count; notFull.signal(); return x; &#125; finally &#123; lock.unlock(); &#125; &#125; &#125; FutureTask FutureTask实现了RunnableFuture接口，则RunnableFuture接口继承了Runnable接口和Future接口，所以FutureTask既能当做一个Runnable直接被Thread执行，也能作为Future用来得到Callable的计算结果。123456789101112131415161718192021222324252627282930313233343536373839404142434445public class Test &#123; public static void main(String[] args) &#123; //第一种方式 ExecutorService executor = Executors.newCachedThreadPool(); Task task = new Task(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); executor.submit(futureTask); executor.shutdown(); //第二种方式，注意这种方式和第一种方式效果是类似的，只不过一个使用的是ExecutorService，一个使用的是Thread /*Task task = new Task(); FutureTask&lt;Integer&gt; futureTask = new FutureTask&lt;Integer&gt;(task); Thread thread = new Thread(futureTask); thread.start();*/ try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e1) &#123; e1.printStackTrace(); &#125; System.out.println("主线程在执行任务"); try &#123; System.out.println("task运行结果"+futureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; System.out.println("所有任务执行完毕"); &#125;&#125;class Task implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; System.out.println("子线程在进行计算"); Thread.sleep(3000); int sum = 0; for(int i=0;i&lt;100;i++) sum += i; return sum; &#125;&#125; Fork/Join框架 Fork/Join框架是Java7提供了的一个用于并行执行任务的框架， 是一个把大任务分割成若干个小任务，最终汇总每个小任务结果后得到大任务结果的框架。 我们再通过Fork和Join这两个单词来理解下Fork/Join框架，Fork就是把一个大任务切分为若干子任务并行的执行，Join就是合并这些子任务的执行结果，最后得到这个大任务的结果。比如计算1+2+。。＋10000，可以分割成10个子任务，每个子任务分别对1000个数进行求和，最终汇总这10个子任务的结果。 工作窃取（work-stealing）算法是指某个线程从其他队列里窃取任务来执行。为什么需要使用工作窃取算法呢？假如我们需要做一个比较大的任务，我们可以把这个任务分割为若干互不依赖的子任务，为了减少线程间的竞争，于是把这些子任务分别放到不同的队列里，并为每个队列创建一个单独的线程来执行队列里的任务，线程和队列一一对应，比如A线程负责处理A队列里的任务。但是有的线程会先把自己队列里的任务干完，而其他线程对应的队列里还有任务等待处理。干完活的线程与其等着，不如去帮其他线程干活，于是它就去其他线程的队列里窃取一个任务来执行。而在这时它们会访问同一个队列，所以为了减少窃取任务线程和被窃取任务线程之间的竞争，通常会使用双端队列，被窃取任务线程永远从双端队列的头部拿任务执行，而窃取任务的线程永远从双端队列的尾部拿任务执行.工作窃取算法的优点是充分利用线程进行并行计算，并减少了线程间的竞争，其缺点是在某些情况下还是存在竞争，比如双端队列里只有一个任务时。并且消耗了更多的系统资源，比如创建多个线程和多个双端队列。 框架介绍：第一步分割任务。首先我们需要有一个fork类来把大任务分割成子任务，有可能子任务还是很大，所以还需要不停的分割，直到分割出的子任务足够小。第二步执行任务并合并结果。分割的子任务分别放在双端队列里，然后几个启动线程分别从双端队列里获取任务执行。子任务执行完的结果都统一放在一个队列里，启动一个线程从队列里拿数据，然后合并这些数据。 Fork/Join使用两个类来完成以上两件事情： ForkJoinTask：我们要使用ForkJoin框架，必须首先创建一个ForkJoin任务。它提供在任务中执行fork()和join()操作的机制，通常情况下我们不需要直接继承ForkJoinTask类，而只需要继承它的子类，Fork/Join框架提供了以下两个子类： RecursiveAction：用于没有返回结果的任务。RecursiveTask ：用于有返回结果的任务。 ForkJoinPool ：ForkJoinTask需要通过ForkJoinPool来执行，任务分割出的子任务会添加到当前工作线程所维护的双端队列中，进入队列的头部。当一个工作线程的队列里暂时没有任务时，它会随机从其他工作线程的队列的尾部获取一个任务。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class CountTask extends RecursiveTask &#123; private static final int THRESHOLD= 2;//阈值 private int start; private int end; public CountTask(int start,int end) &#123; this.start= start; this.end= end; &#125; @Override protected Integer compute() &#123; int sum = 0; //如果任务足够小就计算任务 boolean canCompute = (end-start) &lt;=THRESHOLD; if(canCompute) &#123; for(inti =start; i &lt;=end; i++) &#123; sum += i; &#125; &#125;else&#123; //如果任务大于阀值，就分裂成两个子任务计算 int middle = (start+end) / 2; CountTask leftTask =new CountTask(start, middle); CountTask rightTask =new CountTask(middle + 1,end); //执行子任务 leftTask.fork(); rightTask.fork(); //等待子任务执行完，并得到其结果 int leftResult=leftTask.join(); int rightResult=rightTask.join(); //合并子任务 sum = leftResult + rightResult; &#125; returnsum; &#125; public static void main(String[] args) &#123; ForkJoinPool forkJoinPool =newForkJoinPool(); //生成一个计算任务，负责计算1+2+3+4 CountTask task =newCountTask(1, 4); //执行一个任务 Future result = forkJoinPool.submit(task); try&#123; System.out.println(result.get()); &#125;catch(InterruptedException e) &#123; &#125;catch(ExecutionException e) &#123; &#125; &#125;&#125; BlockingQueue 在新增的Concurrent包中，BlockingQueue很好的解决了多线程中，如何高效安全“传输”数据的问题。通过这些高效并且线程安全的队列类，为我们快速搭建高质量的多线程程序带来极大的便利. ArrayBlockingQueue：是一个用数组实现的有界阻塞队列，此队列按照先进先出（FIFO）的原则对元素进行排序。支持公平锁和非公平锁。【注：每一个线程在获取锁的时候可能都会排队等待，如果在等待时间上，先获取锁的线程的请求一定先被满足，那么这个锁就是公平的。反之，这个锁就是不公平的。公平的获取锁，也就是当前等待时间最长的线程先获取锁】 LinkedBlockingQueue：一个由链表结构组成的有界队列，此队列的长度为Integer.MAX_VALUE。此队列按照先进先出的顺序进行排序。 PriorityBlockingQueue： 一个支持线程优先级排序的无界队列，默认自然序进行排序，也可以自定义实现compareTo()方法来指定元素排序规则，不能保证同优先级元素的顺序。 DelayQueue： 一个实现PriorityBlockingQueue实现延迟获取的无界队列，在创建元素时，可以指定多久才能从队列中获取当前元素。只有延时期满后才能从队列中获取元素。（DelayQueue可以运用在以下应用场景：1.缓存系统的设计：可以用DelayQueue保存缓存元素的有效期，使用一个线程循环查询DelayQueue，一旦能从DelayQueue中获取元素时，表示缓存有效期到了。2.定时任务调度。使用DelayQueue保存当天将会执行的任务和执行时间，一旦从DelayQueue中获取到任务就开始执行，从比如TimerQueue就是使用DelayQueue实现的。） SynchronousQueue： 一个不存储元素的阻塞队列，每一个put操作必须等待take操作，否则不能添加元素。支持公平锁和非公平锁。SynchronousQueue的一个使用场景是在线程池里。Executors.newCachedThreadPool()就使用了SynchronousQueue，这个线程池根据需要（新任务到来时）创建新的线程，如果有空闲线程则会重复使用，线程空闲了60秒后会被回收。 LinkedTransferQueue： 一个由链表结构组成的无界阻塞队列，相当于其它队列，LinkedTransferQueue队列多了transfer和tryTransfer方法。 LinkedBlockingDeque： 一个由链表结构组成的双向阻塞队列。队列头部和尾部都可以添加和移除元素，多线程并发时，可以将锁的竞争最多降到一半。]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[AQS详解]]></title>
    <url>%2F2018%2F09%2F28%2Fconcurrent%2FAQS%E2%80%94%E2%80%94%E9%98%9F%E5%88%97%E5%90%8C%E6%AD%A5%E5%99%A8%2F</url>
    <content type="text"><![CDATA[重写同步器指定方法的时候，需要使用同步器提供的如下3个方法来访问或者修改同步状态。 getState():获取当前同步状态 setState(int newState):设置当前同步状态 compareAndSetState(int expect,int update):使用CAS设置当前状态，该方法能保证状态设置的原子性 同步器可重写的方法与描述如下表 方法名称 描述 protected boolean tryAcquire(int arg) 独占式获取同步状态，实现该方法需要查询当前状态并判断同步状态是否符合预期，然后再进行CAS设置同步状态 protected boolean tryRelease(int arg) 独占式释放同步状态，等待获取同步状态的线程将有机会获取同步状态 protected int tryAcquireShared(int arg) 共享式获取同步状态，返回大于等于0的值，表示获取成功，反之，获取失败 protected boolean tryReleaseShared(int arg) 共享式释放同步状态 protected boolean isHeldExclusively() 当前同步器是否在独占模式下被线程占用，一般该方法表示是否被当前线程所独占 实现自定义同步组件时，将会调用同步器提供的模板方法，这些（部分）模板方法与描述如下表 方法名称 描述 void acqiure(int arg) 独占式获取同步状态，如果当前线程获取同步状态成功，则由该方法返回，否则，将会进入同步队列等待，该方法将会调用重写的tryAcquire(int arg)方法 public final void acquireInterruptibly(int arg) 与acqiure(int arg)相同，但是该方法响应中断，当前线程未获取到同步状态而进入同步队列中，如果当前线程被中断，则该方法会抛出InterruptedException 并返回 public final boolean tryAcquireNanos(int arg, long nanosTimeout) 在acquireInterruptibly(int arg)基础上添加了超时限制，如果当前线程在超时时间内都没有获取到同步状态，那么将会返回false，如果获取到，返回true public final void acquireShared(int arg) 共享式获取同步状态，如果当前线程获取同步状态成功，则由该方法返回，否则，将会进入同步队列等待，与独占式获取的主要区别是在同一时刻可以有多个线程获取到同步状态 public final void acquireSharedInterruptibly(int arg) 与acquireShared(int arg)相同，但是该方法响应中断 public final boolean tryAcquireSharedNanos(int arg, long nanosTimeout) 在acquireSharedInterruptibly(int arg)基础上添加了超时限制 public final boolean release(int arg) 独占式的释放同步状态，该方法会在释放同步状态之后，将同步队列中的第一个节点包含的线程唤醒 public final boolean releaseShared(int arg) 共享式的释放同步状态 public final Collection getQueuedThreads() 获取等待在同步队列上的线程集合 独占锁示例 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import java.io.IOException;import java.io.ObjectInputStream;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.AbstractQueuedSynchronizer;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;public class Mutex implements Lock &#123; //静态内部类，自定义同步器 private static class Sync extends AbstractQueuedSynchronizer &#123; // Reports whether in locked state protected boolean isHeldExclusively() &#123; return getState() == 1; &#125; // Acquires the lock if state is zero public boolean tryAcquire(int acquires) &#123; assert acquires == 1; // Otherwise unused if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; // Releases the lock by setting state to zero protected boolean tryRelease(int releases) &#123; assert releases == 1; // Otherwise unused if (getState() == 0) throw new IllegalMonitorStateException(); setExclusiveOwnerThread(null); setState(0); return true; &#125; // Provides a Condition Condition newCondition() &#123; return new ConditionObject(); &#125; // Deserializes properly private void readObject(ObjectInputStream s) throws IOException, ClassNotFoundException &#123; s.defaultReadObject(); setState(0); // reset to unlocked state &#125; &#125; // The sync object does all the hard work. We just forward to it. private final Sync sync = new Sync(); public void lock() &#123; sync.acquire(1); &#125; public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; public void unlock() &#123; sync.release(1); &#125; public Condition newCondition() &#123; return sync.newCondition(); &#125; public boolean isLocked() &#123; return sync.isHeldExclusively(); &#125; public boolean hasQueuedThreads() &#123; return sync.hasQueuedThreads(); &#125; public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; public boolean tryLock(long timeout, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(timeout)); &#125;&#125; 上例中，Mutex是一个自定义同步组件，同一时刻只允许一个线程占有锁。Mutex中定义的静态内部类继承了AQS并实现了独占式获取和释放同步状态。在tryAcquire(int acquires) 中，如果经过CAS设置成功（同步状态设置为1），则代表获取了同步状态，而在tryRelease(int releases)方法中只是将同步状态重置为0。用户使用Mutex时，并不会直接和内部同步器的实现打交道，而是调用Mutex提供的方法，在Mutex的实现中，以获取锁的Lock()方法为例，只需要在方法实现中调用同步器的模板方法acquire(int args)即可，当前线程调用该方法获取同步状态失败后会被加入到同步队列中等候。 队列同步器实现分析1. 同步队列 Node源码(JDK 1.8)以及主要属性和描述 123456789101112131415161718192021222324252627282930313233static final class Node &#123; static final Node SHARED = new Node(); static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; volatile int waitStatus; volatile Node prev; volatile Node next; volatile Thread thread; Node nextWaiter; final boolean isShared() &#123; return nextWaiter == SHARED; &#125; final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; // Used to establish initial head or SHARED marker &#125; Node(Thread thread, Node mode) &#123; // Used by addWaiter this.nextWaiter = mode; this.thread = thread; &#125; Node(Thread thread, int waitStatus) &#123; // Used by Condition this.waitStatus = waitStatus; this.thread = thread; &#125; &#125; 属性类型与名称 描述 int waitStatus 等待状态。包含以下值：1. CANCELLED： 该节点由于超时或者中断而被取消，节点进入该状态后不会变化。特别的，一个有已取消节点的线程不会再次进入阻塞状态。2. SIGNAL：该节点的后继节点处于阻塞状态（或将会处于阻塞状态），所以当前节点必须通知后续节点，当它释放或者取消的时候；为了避免竞争，acquire方法必须首先声明他们需要一个信号量，然后重试自动获取，然后得到结果，失败或者阻塞。3. CONDITION：当前节点处于一个条件队列中，节点线程等待在Condition上，当其他线程对Condition调用了signal() 方法后，该节点将会从等待队列中转移到同步队列中，加入到对同步状态的获取中。4. PROPAGATE : 表示下一次共享式同步状态获取将会无条件地被传播下去。5. 0 : 初始状态 Node prev 前驱节点 Node next 后继节点 Node nextWaiter 等待队列中的后继节点。如果当前节点是共享的，那么这个字段将是一个SHARED常量，也就是说节点类型(独占和共享)和等待队列的后继节点共用同一个字段 Thread thread 获取同步状态的线程 ​ 节点是构成同步队列（等待队列）的基础，同步器拥有首节点（head） 和尾节点（tail），没有成功获取同步状态的线程将会称为及节点加入该队列的尾部，同步队列的基本结构如下图： ​ 同步器中包含了两个节点类型的引用，一个指向头节点，一个指向尾节点。当一个线程成功获取了同步状态（或者锁），其他线程将无法获取到同步状态，转而被构造成节点并加入到同步队列中，而这个加入队列的过程必须要保证线程安全，因此同步器提供了一个基于CAS的设置尾节点的方法: compareAndSetTail(Node expect, Node update)，它需要传递当前线程“认为”的尾节点和当前节点，只有设置成功后，当前节点才正式与之前的尾节点建立关联。 同步器将节点加入到同步队列的过程如下图： ​ 同步队列遵循FIFO，首节点是获取同步状态成功的节点，首节点的线程在释放同步状态时，会唤醒后继节点，而后继节点将会在获取同步状态成功时将自己设置为首节点，该过程如下图： ​ 设置首节点是通过获取同步状态成功的线程来完成的，由于只有一个线程能够成功获取到同步状态，因此设置头节点的方法并不需要使用CAS来保证，它只需要将首节点设置成为原首节点的后继节点并断开源首节点的next应用即可。 2. 独占式同步状态获取与释放 ​ 通过调用同步器的acquire(int arg) 方法可以获取同步状态，该方法对中断不敏感，也就是由于线程获取同步状态失败后进入同步队列中，后续对线程进行中断操作的时候，线程不会从同步队列中移除。 123456&gt; public final void acquire(int arg) &#123;&gt; if (!tryAcquire(arg) &amp;&amp;&gt; acquireQueued(addWaiter(Node.EXCLUSIVE), arg))&gt; selfInterrupt();&gt; &#125;&gt; ​ 主要逻辑：首先调用自定义同步器实现的tryAcquire(int arg)方法，该方法保证线程安全的获取同步状态，如果同步状态获取失败，则构造同步节点（独占式Node.EXCLUSIVE，同一时刻只能有一个线程成功获取同步状态）并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部，最后调用acquireQueued(Node node,int arg)方法，使得该节点以“死循环”的方式获取同步状态。如果获取不到则阻塞节点中的线程，而被阻塞的线程的唤醒主要依靠前驱节点的出队或者阻塞线程被中断来实现。下面介绍相关方法: 123456789101112131415161718192021222324252627282930&gt; private Node addWaiter(Node mode) &#123;&gt; Node node = new Node(Thread.currentThread(), mode);&gt; // Try the fast path of enq; backup to full enq on failure&gt; Node pred = tail;&gt; if (pred != null) &#123;&gt; node.prev = pred;&gt; if (compareAndSetTail(pred, node)) &#123;&gt; pred.next = node;&gt; return node;&gt; &#125;&gt; &#125;&gt; enq(node);&gt; return node;&gt; &#125;&gt; private Node enq(final Node node) &#123;&gt; for (;;) &#123;&gt; Node t = tail;&gt; if (t == null) &#123; // Must initialize&gt; if (compareAndSetHead(new Node()))&gt; tail = head;&gt; &#125; else &#123;&gt; node.prev = t;&gt; if (compareAndSetTail(t, node)) &#123;&gt; t.next = node;&gt; return t;&gt; &#125;&gt; &#125;&gt; &#125;&gt; &#125;&gt; ​ 以上代码通过使用compareAndSetTail(Node expect, Node update) 方法来确保节点能够被线程安全添加。在enq(final Node node)方法中，同步器通过“死循环”来保证节点的正确添加，在“死循环”中只有通过CAS将节点设置为尾节点后，当前线程才能从该方法中返回，否则，当前线程不断地进行尝试设置。enq（final Node node）将并发添加节点的请求通过CAS变得“串行化”。​ 节点进入同步队列之后，就进入一个自旋的过程，每个节点（或者说每个线程）都在自省地观察，当条件满足，获取到了同步状态，就可以从这个自旋过程中退出，否则依旧留在这个自旋过程中（并会阻塞节点的线程），源码如下： 12345678910111213141516171819202122&gt; final boolean acquireQueued(final Node node, int arg) &#123;&gt; boolean failed = true;&gt; try &#123;&gt; boolean interrupted = false;&gt; for (;;) &#123;&gt; final Node p = node.predecessor();&gt; if (p == head &amp;&amp; tryAcquire(arg)) &#123;&gt; setHead(node);&gt; p.next = null; // help GC&gt; failed = false;&gt; return interrupted;&gt; &#125;&gt; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;&gt; parkAndCheckInterrupt())&gt; interrupted = true;&gt; &#125;&gt; &#125; finally &#123;&gt; if (failed)&gt; cancelAcquire(node);&gt; &#125;&gt; &#125;&gt; ​ 在acquireQueued(final Node node, int arg)方法中，当前线程在“死循环”中尝试获取同步状态，而只有前驱节点是头节点才能够尝试获取同步状态，原因如下： 头结点是成功获取到同步状态的节点，而头结点的线程释放了同步状态之后，将会唤醒其后继节点，后继节点的线程被唤醒后需要检查自己的前驱节点是否是头结点。 维护同步队列的FIFO原则。该方法中，节点自旋获取同步状态的行为如下图： ​ 上图中，由于非首节点线程前驱节点出队或者被中断而从等待状态返回，随后检查自己的前驱节点是否是头节点，如果是则获取同步状态。可以看到节点和节点之间在循环检查的过程中基本不互相通信，而是简单地判断自己的前驱节点是否为头节点，这样就使得节点的释放规则符合FIFO，并且也便于对过早通知的处理（过早通知是指前驱节点不是头节点的线程由于线程中断而被唤醒）。独占式同步状态获取流程如下图：​ 上图中前驱节点为头节点且能够获取同步状态的判断条件和线程进入等待状态是获取同步状态的自旋过程。当同步状态获取成功之后，当前线程从 acquire(int arg)方法返回，如果对于锁这种并发组件而言，代表着当前线程获取了锁。​ 当前线程获取同步状态并执行了相应逻辑之后，就需要释放同步状态，使得后续节点能够继续获取同步状态。通过调用同步器的release(int arg)方法可以释放同步状态，该方法在释放了同步状态之后，会唤醒其后继节点（进而是后继节点重新尝试获取同步状态）。release(int arg) 方法源码如下： 12345678910&gt; public final boolean release(int arg) &#123;&gt; if (tryRelease(arg)) &#123;&gt; Node h = head;&gt; if (h != null &amp;&amp; h.waitStatus != 0)&gt; unparkSuccessor(h);&gt; return true;&gt; &#125;&gt; return false;&gt; &#125;&gt; ​ 该方法执行时，会唤醒头节点的后继节点线程，upparkSuccessor(Node node)方法使用LockSupport来唤醒处于等待状态的线程。 总结： 在获取同步状态的时候，同步器维护一个同步队列，获取状态失败的线程都会被加入到该队列中，并在该队列中进行自旋；移出队列（或者停止自旋）的条件是前驱节点为头节点且成功获取到了同步状态。在释放同步状态时，同步器调用tryRelease(int arg)方法释放同步状态，然后唤醒头节点的后继节点。 3. 共享式同步状态的获取与释放 ​ 共享式获取与独立式获取最主要的区别是同一时刻能否有多个线程同时获取到同步状态。通过调用同步器的acquireShared(int arg)方法可以共享式地获取同步状态，该方法代码如下： 1234567891011121314151617181920212223242526272829303132&gt; public final void acquireShared(int arg) &#123;&gt; if (tryAcquireShared(arg) &lt; 0)&gt; doAcquireShared(arg);&gt; &#125;&gt; private void doAcquireShared(int arg) &#123;&gt; final Node node = addWaiter(Node.SHARED);&gt; boolean failed = true;&gt; try &#123;&gt; boolean interrupted = false;&gt; for (;;) &#123;&gt; final Node p = node.predecessor();&gt; if (p == head) &#123;&gt; int r = tryAcquireShared(arg);&gt; if (r &gt;= 0) &#123;&gt; setHeadAndPropagate(node, r);&gt; p.next = null; // help GC&gt; if (interrupted)&gt; selfInterrupt();&gt; failed = false;&gt; return;&gt; &#125;&gt; &#125;&gt; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;&gt; parkAndCheckInterrupt())&gt; interrupted = true;&gt; &#125;&gt; &#125; finally &#123;&gt; if (failed)&gt; cancelAcquire(node);&gt; &#125;&gt; &#125;&gt; ​ 在acquireShared(int arg)方法中，同步器调用tryAcquireShared(int arg)方法尝试获取同步tryAcquireShared(int arg)方法返回值为int类型，当返回值大于等于0时，表示能够获取到同步状态。因此，在共享式获取的自旋过程中，成功获取到同步状态并退出自旋的条件就是tryAcquireShared(int arg)方法返回值大于等于0。可以看到，在doAcquireShared(int arg)方法的自旋过程中，如果当前节点的前驱为头节点时，尝试获取同步状态，如果返回值大于等于0，表示该次获取同步状态成功并从自旋过程中退出。 共享式获取需要释放同步状态，通过调用releaseShared(int arg)方法可以释放同步状态，该方法代码如下所示。 12345678&gt; public final boolean releaseShared(int arg)&#123;&gt; if(tryReleaseShared(arg))&#123;&gt; doReleaseShared();&gt; return true;&gt; &#125;&gt; return false;&gt; &#125;&gt; ​ 该方法在释放同步状态之后，将会唤醒后续处于等待状态的节点。对于能够支持多个线程同时访问的并发组件（比如Semaphore），它和独占式主要区别在于tryReleaseShared(int arg)方法必须确保同步状态（或者资源数）线程安全释放，一般是通过循环和CAS来保证的，因为释放同步状态的操作会同时来自多个线程。 4.独占式超时获取同步状态 ​ 通过调用通过调用同步器的doAcquireNanos(int arg,long nanosTimeout)方法可以超时获取同步状态，即在指定的时间段内获取同步状态，如果获取到同步状态则返回true，否则，返回false。该方法提供了传统Java同步操作（比如synchronized关键字）所不具备的特性。 在分析该方法的实现前，先介绍一下响应中断的同步状态获取过程。在Java 5之前，当一个线程获取不到锁而被阻塞在synchronized之外时，对该线程进行中断操作，此时该线程的中断标志位会被修改，但线程依旧会阻塞在synchronized上，等待着获取锁。在Java 5中，同步器提供了acquireInterruptibly(int arg)方法，这个方法在等待获取同步状态时，如果当前线程被中断，会立刻返回，并抛出InterruptedException。 超时获取同步状态过程可以被视作响应中断获取同步状态过程的“增强版”，doAcquireNanos(int arg,long nanosTimeout)方法在支持响应中断的基础上，增加了超时获取的特性。针对超时获取，主要需要计算出需要睡眠的时间间隔nanosTimeout，为了防止过早通知，nanosTimeout计算公式为：nanosTimeout-=now-lastTime，其中now为当前唤醒时间，lastTime为上次唤醒时间，如果nanosTimeout大于0则表示超时时间未到，需要继续睡眠nanosTimeout纳秒，反之，表示已经超时，该方法代码如下所示。 123456789101112131415161718192021222324252627282930313233&gt; private boolean doAcquireNanos (int arg, long nanosTimeout) throw InterruptedException&#123;&gt; long lastTime=System.nanoTime();&gt; final Node node=addWaiter(Node.EXCLUSIVE);&gt; boolean failed=true;&gt; try&#123;&gt; for(;;)&#123;&gt; final Node p=node.predecessor();&gt; if(p == head &amp;&amp; tryAcquire(arg))&#123;&gt; setHead(node);&gt; p.next=null;//help gc&gt; failed=false;&gt; return true;&gt; &#125;&gt; if(nanosTimeout &lt;= 0)&gt; return false;&gt; if(shouldParkAfterFailedAcquire(p,node) &gt; &amp;&amp; nanosTimeout &gt; spinForTimeoutThreshold)&gt; LockSupport.parkNanos(this,nanosTimeout);&gt; long now=System.nanoTime();&gt; //计算时间，当前时间now减去睡眠之前的时间lastTime得到已经睡眠的时间delta,&gt; //然后被原有超时时间nanosTimeout减去，得到了还应该睡眠的时间&gt; //即：(now-lastTime)-nanosTimeout&gt; nanosTimeout -=now-lastTime;&gt; lastTime=now;&gt; if(Thread.interrupted())&gt; throw new InterruptedException();&gt; &#125;&gt; &#125;finally&#123;&gt; if(failed)&gt; cancelAcquire(node);&gt; &#125;&gt; &#125;&gt; ​ 该方法在自旋过程中，当节点的前驱节点为头节点时尝试获取同步状态，如果获取成功则从该方法返回，这个过程和独占式同步获取的过程类似，但是在同步状态获取失败的处理上有所不同。如果当前线程获取同步状态失败，则判断是否超时（nanosTimeout小于等于0表示已经超时），如果没有超时，重新计算超时间隔nanosTimeout，然后使当前线程等待nanosTimeout纳秒（当已到设置的超时时间，该线程会从LockSupport.parkNanos(Objectblocker,long nanos)方法返回）。​ 如果nanosTimeout小于等于spinForTimeoutThreshold（1000纳秒）时，将不会使该线程进行超时等待，而是进入快速的自旋过程。原因在于，非常短的超时等待无法做到十分精确，如果这时再进行超时等待，相反会让nanosTimeout的超时从整体上表现得反而不精确。因此，在超时非常短的场景下，同步器会进入无条件的快速自旋。​ 独占式超时获取同步态的流程如图所示：]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[线程安全性]]></title>
    <url>%2F2018%2F09%2F27%2Fconcurrent%2F%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E6%80%A7%2F</url>
    <content type="text"><![CDATA[线程安全性当多个线程访问某个类的时候，不管运行时环境采用何种调度方式或者这些线程按何种顺序交替执行，并且在主调代码中不需要任何额外的同步或者协同，这个类都能表现出正确的行为，那么就称这个类是线程安全的。 原子性 atomic包 atomicXXX: CAS、Unsafe.compareAndSwapInt 123456789101112131415161718192021222324252627282930public class AtomicExample &#123; //请求总数 public static int CLIENT_TOTAL = 5000; //同时并发执行的线程数 public static int THREAD_TOTAL = 200; public static AtomicInteger count = new AtomicInteger(0); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(THREAD_TOTAL); final CountDownLatch countDownLatch = new CountDownLatch(CLIENT_TOTAL); for (int i = 0; i &lt; CLIENT_TOTAL; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println("count : " + count.get()); &#125; private static void add() &#123; count.incrementAndGet(); &#125;&#125; AtomicInteger/AtomicLong/AtomicBoolean可以用原子方式更新的int(long、boolean)值，AtomicInteger可用在应用程序中（如以原子方式增加的计数器），并且不能用于替换Integer。但是，此类确实扩展了Number，允许那些处理基于数字类的工具和实用工具进行统一访问。这里有一点要注意：在32位操作系统中，64位的long和double变量由于会被JVM当作两个分离的32位来进行操作，所以不具有原子性。而使用AtomicLong能让long的操作保持原子型。AtomicLong是作用是对长整形进行原子操作，显而易见，在java1.8中新加入了一个新的原子类LongAdder，该类也可以保证Long类型操作的原子性，相对于AtomicLong，LongAdder有着更高的性能和更好的表现，可以完全替代AtomicLong的来进行原子操作。代码如下 12345678910111213141516171819202122232425262728293031public class AtomicExample2 &#123; //请求总数 public static int CLIENT_TOTAL = 5000; //同时并发执行的线程数 public static int THREAD_TOTAL = 200; public static LongAdder count = new LongAdder(); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(THREAD_TOTAL); final CountDownLatch countDownLatch = new CountDownLatch(CLIENT_TOTAL); for (int i = 0; i &lt; CLIENT_TOTAL; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); add(); semaphore.release(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println("count : " + count); &#125; private static void add() &#123; count.increment(); &#125;&#125; 让方法在多线程环境下只实现一次 123456789101112131415161718192021222324252627282930313233343536public class AtomicExample5 &#123; //请求总数 public static int CLIENT_TOTAL = 5000; //同时并发执行的线程数 public static int THREAD_TOTAL = 200; public static AtomicBoolean atomicBoolean = new AtomicBoolean(false); public static void main(String[] args) throws Exception &#123; ExecutorService executorService = Executors.newCachedThreadPool(); final Semaphore semaphore = new Semaphore(THREAD_TOTAL); final CountDownLatch countDownLatch = new CountDownLatch(CLIENT_TOTAL); for (int i = 0; i &lt; CLIENT_TOTAL; i++) &#123; executorService.execute(() -&gt; &#123; try &#123; semaphore.acquire(); test(); semaphore.release(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); executorService.shutdown(); System.out.println("result : " + atomicBoolean.get()); &#125; private static void test() &#123; if(atomicBoolean.compareAndSet(false,true)) &#123; System.out.println("execute : " + atomicBoolean.get()); &#125; &#125;&#125; AtomicReference、AtomicReferenceFieldUpdater AtomicReference可以用原子方式更新的对象引用。 1234567891011public class AtomicExample3 &#123; private static AtomicReference&lt;Integer&gt; count = new AtomicReference&lt;&gt;(0); public static void main(String[] args) &#123; count.compareAndSet(0, 2); count.compareAndSet(0, 1); count.compareAndSet(1, 3); count.compareAndSet(2, 4); count.compareAndSet(3, 5); System.out.println(count.get()); &#125;&#125; AtomicReferenceFieldUpdater 基于反射的实用工具，可以对指定类的指定volatile字段进行原子更新。该类用于原子数据结构，该结构中同一节点的几个引用字段都独立受原子更新控制。注意，此类中compareAndSet方法的保证弱于其他原子类中该方法的保证。因为此类不能确保所有使用的字段都适合于原子访问目的，所以，对于compareAndSet和set的其他调用，它仅可以保证原子性和可变语义。 123456789101112131415161718192021222324252627282930public class AtomicExample4 &#123; private static AtomicIntegerFieldUpdater&lt;AtomicExample4&gt; updater = AtomicIntegerFieldUpdater.newUpdater(AtomicExample4.class,"count"); public volatile int count = 100; private static AtomicExample4 example4 = new AtomicExample4(); public static void main(String[] args) &#123; if(updater.compareAndSet(example4,100,120)) &#123; System.out.println("update success 1 " + example4.getCount()); &#125; if(updater.compareAndSet(example4, 100 ,120)) &#123; System.out.println("update success 2 " + example4.getCount()); &#125; else &#123; System.out.println("update failed 2 " + example4.getCount()); &#125; &#125; public int getCount() &#123; return count; &#125; public void setCount(int count) &#123; this.count = count; &#125;&#125; AtomicStampedReference AtomicStampedReference原子类是一个带有时间戳的对象引用，在每次修改后，AtomicStampedReference不仅会设置新值而且还会记录更改的时间。当AtomicStampedReference设置对象值时，对象值以及时间戳都必须满足期望值才能写入成功，这也就解决了反复读写时，无法预知值是否已被修改的窘境(解决ABA问题) CAS(Compare and Swap)原理 在JDK 5之前Java语言是靠synchronized关键字保证同步的，这会导致有锁锁机制存在以下问题： 在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。 一个线程持有锁会导致其它所有需要此锁的线程挂起。 如果一个优先级高的线程等待一个优先级低的线程释放锁会导致优先级倒置，引起性能风险。 volatile是不错的机制，但是volatile不能保证原子性。因此对于同步最终还是要回到锁机制上来。独占锁是一种悲观锁，synchronized就是一种独占锁，会导致其它所有需要锁的线程挂起，等待持有锁的线程释放锁。而另一个更加有效的锁就是乐观锁。所谓乐观锁就是，每次不加锁而是假设没有冲突而去完成某项操作，如果因为冲突失败就重试，直到成功为止。乐观锁用到的机制就是CAS，Compare and Swap。CAS的全称是Compare And Swap 即比较交换，其算法核心思想如下: 1执行函数：CAS(V,E,N) 其包含3个参数 V表示要更新的变量 E表示预期值 N表示新值 如果V值等于E值，则将V的值设为N。若V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。通俗的理解就是CAS操作需要我们提供一个期望值，当期望值与当前线程的变量值相同时，说明还没线程修改该值，当前线程可以进行修改，也就是执行CAS操作，但如果期望值与当前线程不符，则说明该值已被其他线程修改，此时不执行更新操作，但可以选择重新读取该变量再尝试再次修改该变量，也可以放弃操作。由于CAS操作属于乐观派，它总认为自己可以成功完成操作，当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败，但失败的线程并不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作，这点从图中也可以看出来。基于这样的原理，CAS操作即使没有锁，同样知道其他线程对共享资源操作影响，并执行相应的处理措施。同时从这点也可以看出，由于无锁操作中没有锁的存在，因此不可能出现死锁的情况，也就是说无锁操作天生免疫死锁。 CAS缺点 CAS虽然很高效的解决了原子操作问题，但是CAS仍然存在三大问题。 循环时间长开销很大。 只能保证一个共享变量的原子操作。 ABA问题。 循环时间长开销很大：我们可以看到getAndAddInt方法执行时，如果CAS失败，会一直进行尝试。如果CAS长时间一直不成功，可能会给CPU带来很大的开销。 只能保证一个共享变量的原子操作：当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁来保证原子性。 什么是ABA问题？ABA问题怎么解决？如果内存地址V初次读取的值是A，并且在准备赋值的时候检查到它的值仍然为A，那我们就能说它的值没有被其他线程改变过了吗？如果在这段期间它的值曾经被改成了B，后来又被改回为A，那CAS操作就会误认为它从来没有被改变过。这个漏洞称为CAS操作的“ABA”问题。Java并发包为了解决这个问题，提供了一个带有标记的原子引用类AtomicStampedReference”，它可以通过控制变量值的版本来保证CAS的正确性。因此，在使用CAS前要考虑清楚“ABA”问题是否会影响程序并发的正确性，如果需要解决ABA问题，改用传统的互斥同步可能会、比原子类更高效。 原子性对比 synchronized:不可中断锁，适合竞争不激烈，可读性好; Lock：可中断锁，竞争激烈时能维持常态; Atomic:竞争激烈时能维持常态，比Lock性能好；但只能同步一个值。 可见性 导致共享变量在线程建不可见的原因 线程交叉执行 重排序结合线程交叉执行 共享变量更新后的值没有在工作内存与主存间及时更新 synchronized JMM关于synchronized的两条规定： 线程解锁前，必须把共享变量的最新值刷新到主内存 线程加锁时，将清空工作内存中共享变量的值，从而使用共享变量时需要从主内存中重新读取最新的值（注意：加锁和解锁是同一把锁） volatile 通过加入内存屏障和禁止重排序优化来实现 对volatile变量写操作时，会在写操作后加入一条store屏障指令，将本地内存中的共享变量值刷新到主内存 对volatile变量读操作时，会在读操作前加入一条load屏障指令,从主内存中读取共享变量 有序性 Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行，却会影响到多线程并发执行的正确性。 volatile,synchronized,lock happeens-before原则Java内存模型中定义的两项操作之间的次序关系，如果说操作A先行发生于操作B，操作A产生的影响能被操作B观察到，“影响”包含了修改了内存中共享变量的值、发送了消息、调用了方法等。 下面是Java内存模型下一些”天然的“happens-before关系，这些happens-before关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们进行随意地重排序。 程序次序规则(Pragram Order Rule)：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环结构。 管程锁定规则(Monitor Lock Rule)：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而”后面“是指时间上的先后顺序。 volatile变量规则(Volatile Variable Rule)：对一个volatile变量的写操作先行发生于后面对这个变量的读取操作，这里的”后面“同样指时间上的先后顺序。 线程启动规则(Thread Start Rule)：Thread对象的start()方法先行发生于此线程的每一个动作。 线程终结规则(Thread Termination Rule)：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join()方法结束，Thread.isAlive()的返回值等作段检测到线程已经终止执行。 线程中断规则(Thread Interruption Rule)：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测是否有中断发生。 对象终结规则(Finalizer Rule)：一个对象初始化完成(构造方法执行完成)先行发生于它的finalize()方法的开始。 传递性(Transitivity)：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。 一个操作”时间上的先发生“不代表这个操作会是”先行发生“，那如果一个操作”先行发生“是否就能推导出这个操作必定是”时间上的先发生 “呢？也是不成立的，一个典型的例子就是指令重排序。所以时间上的先后顺序与happens-before原则之间基本没有什么关系，所以衡量并发安全问题一切必须以happens-before原则为准。]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java线程池]]></title>
    <url>%2F2018%2F09%2F26%2Fconcurrent%2FThreadPool%2F</url>
    <content type="text"><![CDATA[Java线程池 new Thread 弊端 每次新建对象，性能差 线程缺乏统一管理，可能无限制的新建线程，相互竞争，有可能占用过多系统资源导致死机或者OOM 缺少更多的功能，如更多执行，定期执行，线程中断 线程池的好处 重用存在的线程，减少对象的创建、销亡的开销，性能佳 可以有效的控制最大并发线程数，提高系统资源利用率，同时可以避免过多资源竞争，避免阻塞 提供定时执行、定期执行、单线程、并发数控制等功能 TreadPoolExecutor 关键参数 corePoolSize : 核心线程数量 maximumPoolSize: 线程最大线程数 workQueue: 阻塞队列，存储等待执行的任务，很重要，线程池运行过程中产生重大影响 keepAliveTime：线程没有任务执行时，最多保持多久时间 unit: keepAliveTime 的时间单位 threadFactory：线程工厂，用来创建线程 RejectHandler：当拒绝处理任务时的策略 线程池状态： execute():提交任务，交给线程池执行 submit()：提交任务，能够返回执行结果 相当于execute+Future shutdown()：关闭线程池，等待任务都执行完 shutdownNow():关闭线程池，不等待任务都执行完 getTashCount():线程已经执行和未执行的任务总数 getCompletedTaskCount():返回已完成线程数量 getActiveCount():返回当前线程池中正在执行任务的线程数量 getPoolSize():返回线程池当前线程数量 Executor框架接口 线程池类图 Executors.newCachedThreadPool： Executors.newFixedThreadPool: Executors.newSingleThreadExecutor: Executors.newScheduledThreadPool: Executors.newWorkStealingPool: 线程合理配置 CPU密集型任务，就需要尽量压榨CPU，参考值可以设为NCPU + 1 IO密集型任务，参考值可以设置为2*NCPU]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[volatile详解]]></title>
    <url>%2F2018%2F09%2F25%2Fconcurrent%2Fvolatile%2F</url>
    <content type="text"><![CDATA[volatile关键字volatile内存语义 volatile是Java虚拟机提供的轻量级的同步机制。volatile关键字有如下两个作用: 保证被volatile修饰的共享变量对所有线程总数可见的，也就是当一个线程修改了一个被volatile修饰共享变量的值，新值总是可以被其他线程立即得知。 禁止指令重排序优化。 volatile的可见性 关于volatile的可见性作用，我们必须意识到被volatile修饰的变量对所有线程总是立即可见的，对volatile变量的所有写操作总是能立刻反映到其他线程中，但是对于volatile变量运算操作在多线程环境并不保证安全性，如下code 1234567public class VolatileVisibility &#123; public static volatile int i =0; public static void increase()&#123; i++; &#125;&#125;v 正如上述代码所示，i变量的任何改变都会立马反应到其他线程中，但是如此存在多条线程同时调用increase()方法的话，就会出现线程安全问题，毕竟i++操作并不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分两步完成，如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败，因此对于increase方法必须使用synchronized修饰，以便保证线程安全，需要注意的是一旦使用synchronized修饰方法后，由于synchronized本身也具备与volatile相同的特性，即可见性，因此在这样种情况下就完全可以省去volatile修饰变量。code 1234567public class VolatileVisibility &#123; public static int i =0; public static void increase()&#123; i++; &#125;&#125; 现在来看另外一种场景，可以使用volatile修饰变量达到线程安全的目的，如下code1234567891011121314public class VolatileSafe &#123; volatile boolean close; public void close()&#123; close=true; &#125; public void doWork()&#123; while (!close)&#123; System.out.println("safe...."); &#125; &#125;&#125; 由于对于boolean变量close值的修改属于原子性操作，因此可以通过使用volatile修饰变量close，使用该变量对其他线程立即可见，从而达到线程安全的目的。那么JMM是如何实现让volatile变量对其他线程立即可见的呢？实际上，当写一个volatile变量时，JMM会把该线程对应的工作内存中的共享变量值刷新到主内存中，当读取一个volatile变量时，JMM会把该线程对应的工作内存置为无效，那么该线程将只能从主内存中重新读取共享变量。volatile变量正是通过这种写-读方式实现对其他线程可见（但其内存语义实现则是通过内存屏障）。 volatile禁止重排优化 volatile关键字另一个作用就是禁止指令重排优化，从而避免多线程环境下程序出现乱序执行的现象，关于指令重排优化前面已详细分析过，这里主要简单说明一下volatile是如何实现禁止指令重排优化的。先了解一个概念，内存屏障(Memory Barrier）。 内存屏障，又称内存栅栏，是一个CPU指令，它的作用有两个，一是保证特定操作的执行顺序，二是保证某些变量的内存可见性（利用该特性实现volatile的内存可见性）。由于编译器和处理器都能执行指令重排优化。如果在指令间插入一条Memory Barrier则会告诉编译器和CPU，不管什么指令都不能和这条Memory Barrier指令重排序，也就是说通过插入内存屏障禁止在内存屏障前后的指令执行重排序优化。Memory Barrier的另外一个作用是强制刷出各种CPU的缓存数据，因此任何CPU上的线程都能读取到这些数据的最新版本。总之，volatile变量正是通过内存屏障实现其在内存中的语义，即可见性和禁止重排优化。下面看一个非常典型的禁止重排优化的例子，如下： code 123456789101112131415161718192021public class DoubleCheckLock &#123; private static DoubleCheckLock instance; private DoubleCheckLock()&#123;&#125; public static DoubleCheckLock getInstance()&#123; //第一次检测 if (instance==null)&#123; //同步 synchronized (DoubleCheckLock.class)&#123; if (instance == null)&#123; //多线程环境下可能会出现问题的地方 instance = new DoubleCheckLock(); &#125; &#125; &#125; return instance; &#125;&#125; 上述代码一个经典的单例的双重检测的代码，这段代码在单线程环境下并没有什么问题，但如果在多线程环境下就可以出现线程安全问题。原因在于某一个线程执行到第一次检测，读取到的instance不为null时，instance的引用对象可能没有完成初始化。因为instance = new DoubleCheckLock()可以分为以下3步完成(伪代码)。 123 memory = allocate(); //1.分配对象内存空间instance(memory); //2.初始化对象instance = memory; //3.设置instance指向刚分配的内存地址，此时instance！=null 由于步骤1和步骤2间可能会重排序，如下：code123memory = allocate(); //1.分配对象内存空间instance = memory; //3.设置instance指向刚分配的内存地址，此时instance！=null，但是对象还没有初始化完成！instance(memory); //2.初始化对象 由于步骤2和步骤3不存在数据依赖关系，而且无论重排前还是重排后程序的执行结果在单线程中并没有改变，因此这种重排优化是允许的。但是指令重排只会保证串行语义的执行的一致性(单线程)，但并不会关心多线程间的语义一致性。所以当一条线程访问instance不为null时，由于instance实例未必已初始化完成，也就造成了线程安全问题。那么该如何解决呢，很简单，我们使用volatile禁止instance变量被执行指令重排优化即可。code12//禁止指令重排优化 private volatile static DoubleCheckLock instance; 总而言之，我们应该清楚知道，JMM就是一组规则，这组规则意在解决在并发编程可能出现的线程安全问题，并提供了内置解决方案（happen-before原则）及其外部可使用的同步手段(synchronized/volatile等)，确保了程序执行在多线程环境中的应有的原子性，可视性及其有序性。]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[synchronized原理]]></title>
    <url>%2F2018%2F09%2F25%2Fconcurrent%2Fsynchronized%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[synchronized原理java对象头 synchronized用的锁是存在java对象头里的。Java对象头长度如下表： 长度 内容 说明 32/64bit Mark Word 存储对象的hashCode或锁信息等 32/64bit Class Metadata Address 存储到对象类型数据的指针 32/64bit Array length 数组的长度(如果当前对象是数组) Java对象头的存储结构 32位虚拟机： 64位虚拟街 锁升级与对比 锁一共有4种状态：级别从高到低依次为：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态。这几个状态会随着竞争情况自检升级，但不能降级。 偏向锁 经过HotSpot的作者大量的研究发现，大多数时候是不存在锁竞争的，常常是一个线程多次获得同一个锁，因此如果每次都要竞争锁会增大很多没有必要付出的代价，为了降低获取锁的代价，才引入的偏向锁。 偏向锁初始化流程图 轻量级锁以及膨胀流程图 锁的优缺点对比 锁 优点 缺点 使用场景 偏向锁 加锁和解锁不需要额外的消耗，和执行非同步方法相比仅存在纳秒级差距 如果线程间存在锁竞争，会带来额外的锁撤销的消耗 适用于只有一个线程访问同步块的情景 轻量级锁 竞争的线程不会阻塞，提高了程序的响应速度 如果始终得不到锁竞争线程，使用自旋会消耗CPU 追求响应时间，同步块执行速度非常快 重量级锁 线程竞争不使用自旋，不会消耗CPU 线程阻塞，响应时间缓慢 追求吞吐量，同步块执行时间较长]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F09%2F23%2Fconcurrent%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[synchronized关键字解析]]></title>
    <url>%2F2018%2F09%2F21%2Fconcurrent%2Fsynchronized%2F</url>
    <content type="text"><![CDATA[synchronized关键字 线程安全是并发编程中的重要关注点，应该注意到的是，造成线程安全问题的主要诱因有两点，一是存在共享数据(也称临界资源)，二是存在多条线程共同操作共享数据。因此为了解决这个问题，我们可能需要这样一个方案，当存在多个线程操作共享数据时，需要保证同一时刻有且只有一个线程在操作共享数据，其他线程必须等到该线程处理完数据后再进行，这种方式有个高尚的名称叫互斥锁，即能达到互斥访问目的的锁，也就是说当一个共享数据被当前正在访问的线程加上互斥锁后，在同一个时刻，其他线程只能处于等待的状态，直到当前线程处理完毕释放该锁。在 Java 中，关键字 synchronized可以保证在同一个时刻，只有一个线程可以执行某个方法或者某个代码块(主要是对方法或者代码块中存在共享数据的操作)，同时我们还应该注意到synchronized另外一个重要的作用，synchronized可保证一个线程的变化(主要是共享数据的变化)被其他线程所看到（保证可见性，完全可以替代Volatile功能），这点确实也是很重要的。 synchronized的四种应用方式 修饰实例方法，作用于当前实例加锁，进入同步代码前要获得当前实例的锁。 修饰静态方法，作用于当前类对象加锁，进入同步代码前要获得当前类对象的锁。 修饰代码块，指定加锁对象，对给定对象加锁，进入同步代码库前要获得给定对象的锁。 修饰一个类 ，括号括起来的，作用于所有对象。 synchronized作用于实例方法 所谓的实例对象锁就是用synchronized修饰实例对象中的实例方法，注意是实例方法不包括静态方法，如下 12345678910111213141516171819202122232425262728293031public class AccountingSync implements Runnable&#123; //共享资源(临界资源) static int i=0; /** * synchronized 修饰实例方法 */ public synchronized void increase()&#123; i++; &#125; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; AccountingSync instance=new AccountingSync(); Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(i); &#125; /** * 输出结果: * 2000000 */&#125; 上述代码中，我们开启两个线程操作同一个共享资源即变量i，由于i++;操作并不具备原子性，该操作是先读取值，然后写回一个新值，相当于原来的值加上1，分两步完成，如果第二个线程在第一个线程读取旧值和写回新值期间读取i的域值，那么第二个线程就会与第一个线程一起看到同一个值，并执行相同值的加1操作，这也就造成了线程安全失败，因此对于increase方法必须使用synchronized修饰，以便保证线程安全。此时我们应该注意到synchronized修饰的是实例方法increase，在这样的情况下，当前线程的锁便是实例对象instance，注意Java中的线程同步锁可以是任意对象。从代码执行结果来看确实是正确的，倘若我们没有使用synchronized关键字，其最终输出结果就很可能小于2000000，这便是synchronized关键字的作用。这里我们还需要意识到，当一个线程正在访问一个对象的 synchronized 实例方法，那么其他线程不能访问该对象的其他 synchronized 方法，毕竟一个对象只有一把锁，当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他synchronized实例方法，但是其他线程还是可以访问该实例对象的其他非synchronized方法，当然如果是一个线程 A 需要访问实例对象 obj1 的 synchronized 方法 f1(当前对象锁是obj1)，另一个线程 B 需要访问实例对象 obj2 的 synchronized 方法 f2(当前对象锁是obj2)，这样是允许的，因为两个实例对象锁并不同相同，此时如果两个线程操作数据并非共享的，线程安全是有保障的，遗憾的是如果两个线程操作的是共享数据，那么线程安全就有可能无法保证了，如下代码将演示出该现象123456789101112131415161718192021222324public class AccountingSyncBad implements Runnable&#123; static int i=0; public synchronized void increase()&#123; i++; &#125; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; //new新实例 Thread t1=new Thread(new AccountingSyncBad()); //new新实例 Thread t2=new Thread(new AccountingSyncBad()); t1.start(); t2.start(); //join含义:当前线程A等待thread线程终止之后才能从thread.join()返回 t1.join(); t2.join(); System.out.println(i); &#125;&#125; 上述代码与前面不同的是我们同时创建了两个新实例AccountingSyncBad，然后启动两个不同的线程对共享变量i进行操作，但很遗憾操作结果是1452317而不是期望结果2000000，因为上述代码犯了严重的错误，虽然我们使用synchronized修饰了increase方法，但却new了两个不同的实例对象，这也就意味着存在着两个不同的实例对象锁，因此t1和t2都会进入各自的对象锁，也就是说t1和t2线程使用的是不同的锁，因此线程安全是无法保证的。解决这种困境的的方式是将synchronized作用于静态的increase方法，这样的话，对象锁就当前类对象，由于无论创建多少个实例对象，但对于的类对象拥有只有一个，所有在这样的情况下对象锁就是唯一的。下面我们看看如何使用将synchronized作用于静态的increase方法。 synchronized作用于静态方法 当synchronized作用于静态方法时，其锁就是当前类的class对象锁。由于静态成员不专属于任何一个实例对象，是类成员，因此通过class对象锁可以控制静态 成员的并发操作。需要注意的是如果一个线程A调用一个实例对象的非static synchronized方法，而线程B需要调用这个实例对象所属类的静态 synchronized方法，是允许的，不会发生互斥现象，因为访问静态 synchronized 方法占用的锁是当前类的class对象，而访问非静态 synchronized 方法占用的锁是当前实例对象锁，看如下代码：123456789101112131415161718192021222324252627282930313233343536public class AccountingSyncClass implements Runnable&#123; static int i=0; /** * 作用于静态方法,锁是当前class对象,也就是 * AccountingSyncClass类对应的class对象 */ public static synchronized void increase()&#123; i++; &#125; /** * 非静态,访问时锁不一样不会发生互斥 */ public synchronized void increase4Obj()&#123; i++; &#125; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; increase(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; //new新实例 Thread t1=new Thread(new AccountingSyncClass()); //new心事了 Thread t2=new Thread(new AccountingSyncClass()); //启动线程 t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); &#125;&#125; 由于synchronized关键字修饰的是静态increase方法，与修饰实例方法不同的是，其锁对象是当前类的class对象。注意代码中的increase4Obj方法是实例方法，其对象锁是当前实例对象，如果别的线程调用该方法，将不会产生互斥现象，毕竟锁对象不同，但我们应该意识到这种情况下可能会发现线程安全问题(操作了共享静态变量i)。 synchronized同步代码块 除了使用关键字修饰实例方法和静态方法外，还可以使用同步代码块，在某些情况下，我们编写的方法体可能比较大，同时存在一些比较耗时的操作，而需要同步的代码又只有一小部分，如果直接对整个方法进行同步操作，可能会得不偿失，此时我们可以使用同步代码块的方式对需要同步的代码进行包裹，这样就无需对整个方法进行同步操作了，同步代码块的使用示例如下：code 1234567891011121314151617181920212223public class AccountingSync implements Runnable&#123; static AccountingSync instance=new AccountingSync(); static int i=0; @Override public void run() &#123; //省略其他耗时操作.... //使用同步代码块对变量i进行同步操作,锁对象为instance //synchronized(AccountingSync.class) //synchronized(this) synchronized(instance)&#123; for(int j=0;j&lt;1000000;j++)&#123; i++; &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); &#125;&#125; 从代码看出，将synchronized作用于一个给定的实例对象instance，即当前实例对象就是锁对象，每次当线程进入synchronized包裹的代码块时就会要求当前线程持有instance实例对象锁，如果当前有其他线程正持有该对象锁，那么新到的线程就必须等待，这样也就保证了每次只有一个线程执行i++;操作。当然除了instance作为对象外，我们还可以使用this对象(代表当前实例)或者当前类的class对象作为锁，如下代码：12345678910111213//this,当前实例对象锁synchronized(this)&#123; for(int j=0;j&lt;1000000;j++)&#123; i++; &#125;&#125;//class对象锁synchronized(AccountingSync.class)&#123; for(int j=0;j&lt;1000000;j++)&#123; i++; &#125;&#125; Java虚拟机对synchronized的优化 锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级，关于重量级锁，前面我们已详细分析过，下面我们将介绍偏向锁和轻量级锁以及JVM的其他优化手段，这里并不打算深入到每个锁的实现和转换过程更多地是阐述Java虚拟机所提供的每个锁的核心优化思想，毕竟涉及到具体过程比较繁琐，如需了解详细过程可以查阅《深入理解Java虚拟机原理》。 偏向锁偏向锁是Java 6之后加入的新锁，它是一种针对加锁操作的优化手段，经过研究发现，在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了减少同一线程获取锁(会涉及到一些CAS操作,耗时)的代价而引入偏向锁。偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时Mark Word 的结构也变为偏向锁结构，当这个线程再次请求锁时，无需再做任何同步操作，即获取锁的过程，这样就省去了大量有关锁申请的操作，从而也就提高程序的性能。所以，对于没有锁竞争的场合，偏向锁有很好的优化效果，毕竟极有可能连续多次是同一个线程申请相同的锁。但是对于锁竞争比较激烈的场合，偏向锁就失效了，因为这样场合极有可能每次申请锁的线程都是不相同的，因此这种场合下不应该使用偏向锁，否则会得不偿失，需要注意的是，偏向锁失败后，并不会立即膨胀为重量级锁，而是先升级为轻量级锁。下面我们接着了解轻量级锁。 轻量级锁倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手段(1.6之后加入的)，此时Mark Word 的结构也变为轻量级锁的结构。轻量级锁能够提升程序性能的依据是“对绝大部分的锁，在整个同步周期内都不存在竞争”，注意这是经验数据。需要了解的是，轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间访问同一锁的场合，就会导致轻量级锁膨胀为重量级锁。 自旋锁轻量级锁失败后，虚拟机为了避免线程真实地在操作系统层面挂起，还会进行一项称为自旋锁的优化手段。这是基于在大多数情况下，线程持有锁的时间都不会太长，如果直接挂起操作系统层面的线程可能会得不偿失，毕竟操作系统实现线程之间的切换时需要从用户态转换到核心态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高，因此自旋锁会假设在不久将来，当前的线程可以获得锁，因此虚拟机会让当前想要获取锁的线程做几个空循环(这也是称为自旋的原因)，一般不会太久，可能是50个循环或100循环，在经过若干次循环后，如果得到锁，就顺利进入临界区。如果还不能获得锁，那就会将线程在操作系统层面挂起，这就是自旋锁的优化方式，这种方式确实也是可以提升效率的。最后没办法也就只能升级为重量级锁了。 锁消除消除锁是虚拟机另外一种锁的优化，这种优化更彻底，Java虚拟机在JIT编译时(可以简单理解为当某段代码即将第一次被执行时进行编译，又称即时编译)，通过对运行上下文的扫描，去除不可能存在共享资源竞争的锁，通过这种方式消除没有必要的锁，可以节省毫无意义的请求锁时间，如下StringBuffer的append是一个同步方法，但是在add方法中的StringBuffer属于一个局部变量，并且不会被其他线程所使用，因此StringBuffer不可能存在共享资源竞争的情景，JVM会自动将其锁消除。1234567891011121314151617public class StringBufferRemoveSync &#123; public void add(String str1, String str2) &#123; //StringBuffer是线程安全,由于sb只会在append方法中使用,不可能被其他线程引用 //因此sb属于不可能共享的资源,JVM会自动消除内部的锁 StringBuffer sb = new StringBuffer(); sb.append(str1).append(str2); &#125; public static void main(String[] args) &#123; StringBufferRemoveSync rmsync = new StringBufferRemoveSync(); for (int i = 0; i &lt; 10000000; i++) &#123; rmsync.add("abc", "123"); &#125; &#125;&#125; synchronized的可重入性 从互斥锁的设计上来说，当一个线程试图操作一个由其他线程持有的对象锁的临界资源时，将会处于阻塞状态，但当一个线程再次请求自己持有对象锁的临界资源时，这种情况属于重入锁，请求将会成功，在java中synchronized是基于原子性的内部锁机制，是可重入的，因此在一个线程调用synchronized方法的同时在其方法体内部调用该对象另一个synchronized方法，也就是说一个线程得到一个对象锁后再次请求该对象锁，是允许的，这就是synchronized的可重入性。如下：1234567891011121314151617181920212223242526272829public class AccountingSync implements Runnable&#123; static AccountingSync instance=new AccountingSync(); static int i=0; static int j=0; @Override public void run() &#123; for(int j=0;j&lt;1000000;j++)&#123; //this,当前实例对象锁 synchronized(this)&#123; i++; increase();//synchronized的可重入性 &#125; &#125; &#125; public synchronized void increase()&#123; j++; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread t1=new Thread(instance); Thread t2=new Thread(instance); t1.start();t2.start(); t1.join();t2.join(); System.out.println(i); &#125;&#125; 正如代码所演示的，在获取当前实例对象锁后进入synchronized代码块执行同步代码，并在代码块中调用了当前实例对象的另外一个synchronized方法，再次请求当前实例锁时，将被允许，进而执行方法体代码，这就是重入锁最直接的体现，需要特别注意另外一种情况，当子类继承父类时，子类也是可以通过可重入锁调用父类的同步方法。注意由于synchronized是基于monitor实现的，因此每次重入，monitor中的计数器仍会加1。 线程中断与synchronized正如中断二字所表达的意义，在线程运行(run方法)中间打断它，在Java中，提供了以下3个有关线程中断的方法12345678//中断线程（实例方法）public void Thread.interrupt();//判断线程是否被中断（实例方法）public boolean Thread.isInterrupted();//判断是否被中断并清除当前中断状态（静态方法）public static boolean Thread.interrupted(); 当一个线程处于被阻塞状态或者试图执行一个阻塞操作时，使用Thread.interrupt()方式中断该线程，注意此时将会抛出一个InterruptedException的异常，同时中断状态将会被复位(由中断状态改为非中断状态)，如下代码将演示该过程：12345678910111213141516171819202122232425262728293031public class InterruputSleepThread3 &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread() &#123; @Override public void run() &#123; //while在try中，通过异常中断就可以退出run循环 try &#123; while (true) &#123; //当前线程处于阻塞状态，异常必须捕捉处理，无法往外抛出 TimeUnit.SECONDS.sleep(2); &#125; &#125; catch (InterruptedException e) &#123; System.out.println("Interruted When Sleep"); boolean interrupt = this.isInterrupted(); //中断状态被复位 System.out.println("interrupt:"+interrupt); &#125; &#125; &#125;; t1.start(); TimeUnit.SECONDS.sleep(2); //中断处于阻塞状态的线程 t1.interrupt(); /** * 输出结果: Interruted When Sleep interrupt:false */ &#125;&#125; 如上述代码所示，我们创建一个线程，并在线程中调用了sleep方法从而使用线程进入阻塞状态，启动线程后，调用线程实例对象的interrupt方法中断阻塞异常，并抛出InterruptedException异常，此时中断状态也将被复位。这里有些人可能会诧异，为什么不用Thread.sleep(2000)而是用TimeUnit.SECONDS.sleep(2);其实原因很简单，前者使用时并没有明确的单位说明，而后者非常明确表达秒的单位，事实上后者的内部实现最终还是调用了Thread.sleep(2000)，但为了编写的代码语义更清晰，建议使用TimeUnit.SECONDS.sleep(2)的方式，注意TimeUnit是个枚举类型。ok~，除了阻塞中断的情景，我们还可能会遇到处于运行期且非阻塞的状态的线程，这种情况下，直接调用Thread.interrupt()中断线程是不会得到任响应的，如下代码，将无法中断非阻塞状态下的线程：1234567891011121314151617181920212223public class InterruputThread &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1=new Thread()&#123; @Override public void run()&#123; while(true)&#123; System.out.println("未被中断"); &#125; &#125; &#125;; t1.start(); TimeUnit.SECONDS.sleep(2); t1.interrupt(); /** * 输出结果(无限执行): 未被中断 未被中断 未被中断 ...... */ &#125;&#125; 虽然我们调用了interrupt方法，但线程t1并未被中断，因为处于非阻塞状态的线程需要我们手动进行中断检测并结束程序，改进后代码如下：123456789101112131415161718192021222324252627public class InterruputThread &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1=new Thread()&#123; @Override public void run()&#123; while(true)&#123; //判断当前线程是否被中断 if (this.isInterrupted())&#123; System.out.println("线程中断"); break; &#125; &#125; System.out.println("已跳出循环,线程中断!"); &#125; &#125;; t1.start(); TimeUnit.SECONDS.sleep(2); t1.interrupt(); /** * 输出结果: 线程中断 已跳出循环,线程中断! */ &#125;&#125; 是的，我们在代码中使用了实例方法isInterrupted判断线程是否已被中断，如果被中断将跳出循环以此结束线程,注意非阻塞状态调用interrupt()并不会导致中断状态重置。综合所述，可以简单总结一下中断两种情况，一种是当线程处于阻塞状态或者试图执行一个阻塞操作时，我们可以使用实例方法interrupt()进行线程中断，执行中断操作后将会抛出interruptException异常(该异常必须捕捉无法向外抛出)并将中断状态复位，另外一种是当线程处于运行状态时，我们也可调用实例方法interrupt()进行线程中断，但同时必须手动判断中断状态，并编写中断线程的代码(其实就是结束run方法体的代码)。有时我们在编码时可能需要兼顾以上两种情况，那么就可以如下编写：12345678910public void run()&#123; try &#123; //判断当前线程是否已中断,注意interrupted方法是静态的,执行后会对中断状态进行复位 while (!Thread.interrupted()) &#123; TimeUnit.SECONDS.sleep(2); &#125; &#125; catch (InterruptedException e) &#123; &#125;&#125; 中断与synchronized 事实上线程的中断操作对于正在等待获取的锁对象的synchronized方法或者代码块并不起作用，也就是对于synchronized来说，如果一个线程在等待锁，那么结果只有两种，要么它获得这把锁继续执行，要么它就保存等待，即使调用中断线程的方法，也不会生效。演示代码如下code 123456789101112131415161718192021222324252627282930313233343536373839404142public class SynchronizedBlocked implements Runnable&#123; public synchronized void f() &#123; System.out.println("Trying to call f()"); while(true) // Never releases lock Thread.yield(); &#125; /** * 在构造器中创建新线程并启动获取对象锁 */ public SynchronizedBlocked() &#123; //该线程已持有当前实例锁 new Thread() &#123; public void run() &#123; f(); // Lock acquired by this thread &#125; &#125;.start(); &#125; public void run() &#123; //中断判断 while (true) &#123; if (Thread.interrupted()) &#123; System.out.println("中断线程!!"); break; &#125; else &#123; f(); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; SynchronizedBlocked sync = new SynchronizedBlocked(); Thread t = new Thread(sync); //启动后调用f()方法,无法获取当前实例锁处于等待状态 t.start(); TimeUnit.SECONDS.sleep(1); //中断线程,无法生效 t.interrupt(); &#125;&#125; 我们在SynchronizedBlocked构造函数中创建一个新线程并启动获取调用f()获取到当前实例锁，由于SynchronizedBlocked自身也是线程，启动后在其run方法中也调用了f()，但由于对象锁被其他线程占用，导致t线程只能等到锁，此时我们调用了t.interrupt();但并不能中断线程。 等待唤醒机制与synchronized 所谓等待唤醒机制本篇主要指的是notify/notifyAll和wait方法，在使用这3个方法时，必须处于synchronized代码块或者synchronized方法中，否则就会抛出IllegalMonitorStateException异常，这是因为调用这几个方法前必须拿到当前对象的监视器monitor对象，也就是说notify/notifyAll和wait方法依赖于monitor对象，在前面的分析中，我们知道monitor 存在于对象头的Mark Word 中(存储monitor引用指针)，而synchronized关键字可以获取 monitor ，这也就是为什么notify/notifyAll和wait方法必须在synchronized代码块或者synchronized方法调用的原因。12345synchronized (obj) &#123; obj.wait(); obj.notify(); obj.notifyAll(); &#125; 需要特别理解的一点是，与sleep方法不同的是wait方法调用完成后，线程将被暂停，但wait方法将会释放当前持有的监视器锁(monitor)，直到有线程调用notify/notifyAll方法后方能继续执行，而sleep方法只让线程休眠并不释放锁。同时notify/notifyAll方法调用后，并不会马上释放监视器锁，而是在相应的synchronized(){}/synchronized方法执行结束后才自动释放锁。]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JAVA内存模型]]></title>
    <url>%2F2018%2F09%2F17%2Fconcurrent%2FJava%E5%86%85%E5%AD%98%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[Java内存模型(Java Memory Model, JMM)Java内存区域 Java运行时数据区分为下面几个内存区域 PC寄存器/程序计数器 严格来说是一个数据结构，用于保存当前正在执行的程序的内存地址，由于Java是支持多线程执行的，所以程序执行的轨迹不可能一直都是线性执行。当有多个线程交叉执行时，被中断的线程的程序当前执行到哪条内存地址必然要保存下来，以便用于被中断的线程恢复执行时再按照被中断时的指令地址继续执行下去。为了线程切换后能恢复到正确的执行位置，每个线程都需要有一个独立的程序计数器，各个线程之间计数器互不影响，独立存储，我们称这类内存区域为“线程私有”的内存,这在某种程度上有点类似于“ThreadLocal”，是线程安全的 Java栈 Java Stack Java栈总是与线程关联在一起的，每当创建一个线程，JVM就会为该线程创建对应的Java栈，在这个Java栈中又会包含多个栈帧(Stack Frame)，这些栈帧是与每个方法关联起来的，每运行一个方法就创建一个栈帧，每个栈帧会含有一些局部变量、操作栈和方法返回值等信息。每当一个方法执行完成时，该栈帧就会弹出栈帧的元素作为这个方法的返回值，并且清除这个栈帧，Java栈的栈顶的栈帧就是当前正在执行的活动栈，也就是当前正在执行的方法，PC寄存器也会指向该地址。只有这个活动的栈帧的本地变量可以被操作栈使用，当在这个栈帧中调用另外一个方法时，与之对应的一个新的栈帧被创建，这个新创建的栈帧被放到Java栈的栈顶，变为当前的活动栈。同样现在只有这个栈的本地变量才能被使用，当这个栈帧中所有指令都完成时，这个栈帧被移除Java栈，刚才的那个栈帧变为活动栈帧，前面栈帧的返回值变为这个栈帧的操作栈的一个操作数。由于Java栈是与线程对应起来的，Java栈数据不是线程共有的，所以不需要关心其数据一致性，也不会存在同步锁的问题。在Java虚拟机规范中，对这个区域规定了两种异常状况：如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常；如果虚拟机可以动态扩展，如果扩展时无法申请到足够的内存，就会抛出OutOfMemoryError异常。在Hot Spot虚拟机中，可以使用-Xss参数来设置栈的大小。栈的大小直接决定了函数调用的可达深度。 堆 Heap 堆是JVM所管理的内存中国最大的一块，是被所有Java线程锁共享的，不是线程安全的，在JVM启动时创建。堆是存储Java对象的地方，这一点Java虚拟机规范中描述是：所有的对象实例以及数组都要在堆上分配。Java堆是GC管理的主要区域，从内存回收的角度来看，由于现在GC基本都采用分代收集算法，所以Java堆还可以细分为：新生代和老年代；新生代再细致一点有Eden空间、From Survivor空间、To Survivor空间等。 方法区Method Area 方法区存放了要加载的类的信息（名称、修饰符等）、类中的静态常量、类中定义为final类型的常量、类中的Field信息、类中的方法信息，当在程序中通过Class对象的getName.isInterface等方法来获取信息时，这些数据都来源于方法区。方法区是被Java线程锁共享的，不像Java堆中其他部分一样会频繁被GC回收，它存储的信息相对比较稳定，在一定条件下会被GC，当方法区要使用的内存超过其允许的大小时，会抛出OutOfMemory的错误信息。方法区也是堆中的一部分，就是我们通常所说的Java堆中的永久区 Permanet Generation，大小可以通过参数来设置,可以通过-XX:PermSize指定初始值，-XX:MaxPermSize指定最大值。 常量池Constant Pool 常量池本身是方法区中的一个数据结构。常量池中存储了如字符串、final变量值、类名和方法名常量。常量池在编译期间就被确定，并保存在已编译的.class文件中。一般分为两类：字面量和应用量。字面量就是字符串、final变量等。类名和方法名属于引用量。引用量最常见的是在调用方法的时候，根据方法名找到方法的引用，并以此定为到函数体进行函数代码的执行。引用量包含：类和接口的权限定名、字段的名称和描述符，方法的名称和描述符。 本地方法栈Native Method Stack 本地方法栈和Java栈所发挥的作用非常相似，区别不过是Java栈为JVM执行Java方法服务，而本地方法栈为JVM执行Native方法服务。本地方法栈也会抛出StackOverflowError和OutOfMemoryError异常。 主内存和工作内存： Java内存模型的主要目标是定义程序中各个变量的访问规则，即在JVM中将变量存储到内存和从内存中取出变量这样的底层细节。此处的变量与Java编程里面的变量有所不同步，它包含了实例字段、静态字段和构成数组对象的元素，但不包含局部变量和方法参数，因为后者是线程私有的，不会共享，当然不存在数据竞争问题（如果局部变量是一个reference引用类型，它引用的对象在Java堆中可被各个线程共享，但是reference引用本身在Java栈的局部变量表中，是线程私有的）。为了获得较高的执行效能，Java内存模型并没有限制执行引起使用处理器的特定寄存器或者缓存来和主内存进行交互，也没有限制即时编译器进行调整代码执行顺序这类优化措施。JMM规定了所有的变量都存储在主内存（Main Memory）中。每个线程还有自己的工作内存（Working Memory）,线程的工作内存中保存了该线程使用到的变量的主内存的副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量（volatile变量仍然有工作内存的拷贝，但是由于它特殊的操作顺序性规定，所以看起来如同直接在主内存中读写访问一般）。不同的线程之间也无法直接访问对方工作内存中的变量，线程之间值的传递都需要通过主内存来完成。 线程1和线程2要想进行数据的交换一般要经历下面的步骤： 线程1把工作内存1中的更新过的共享变量刷新到主内存中去。 线程2到主内存中去读取线程1刷新过的共享变量，然后copy一份到工作内存2中去。并发编程三原则：原子性、可见性、有序性 原子性（Atomicity）：一个操作不能被打断，要么全部执行完毕，要么不执行。在这点上有点类似于事务操作，要么全部执行成功，要么回退到执行该操作之前的状态。 基本类型数据的访问大都是原子操作，long 和double类型的变量是64位，但是在32位JVM中，32位的JVM会将64位数据的读写操作分为2次32位的读写操作来进行，这就导致了long、double类型的变量在32位虚拟机中是非原子操作，数据有可能会被破坏，也就意味着多个线程在并发访问的时候是线程非安全的。 可见性：一个线程对共享变量做了修改之后，其他的线程立即能够看到（感知到）该变量这种修改（变化）。 Java内存模型是通过将在工作内存中的变量修改后的值同步到主内存，在读取变量前从主内存刷新最新值到工作内存中，这种依赖主内存的方式来实现可见性的。无论是普通变量还是volatile变量都是如此，区别在于：volatile的特殊规则保证了volatile变量值修改后的新值立刻同步到主内存，每次使用volatile变量前立即从主内存中刷新，因此volatile保证了多线程之间的操作变量的可见性，而普通变量则不能保证这一点。除了volatile关键字能实现可见性之外，还有synchronized,Lock，final也是可以的。使用synchronized关键字，在同步方法/同步块开始时（Monitor Enter）,使用共享变量时会从主内存中刷新变量值到工作内存中（即从主内存中读取最新值到线程私有的工作内存中），在同步方法/同步块结束时(Monitor Exit),会将工作内存中的变量值同步到主内存中去（即将线程私有的工作内存中的值写入到主内存进行同步）。使用Lock接口的最常用的实现ReentrantLock(重入锁)来实现可见性：当我们在方法的开始位置执行lock.lock()方法，这和synchronized开始位置（Monitor Enter）有相同的语义，即使用共享变量时会从主内存中刷新变量值到工作内存中（即从主内存中读取最新值到线程私有的工作内存中），在方法的最后finally块里执行lock.unlock()方法，和synchronized结束位置（Monitor Exit）有相同的语义,即会将工作内存中的变量值同步到主内存中去（即将线程私有的工作内存中的值写入到主内存进行同步）。final关键字的可见性是指：被final修饰的变量，在构造函数数一旦初始化完成，并且在构造函数中并没有把“this”的引用传递出去（“this”引用逃逸是很危险的，其他的线程很可能通过该引用访问到只“初始化一半”的对象），那么其他线程就可以看到final变量的值。 有序性：对于一个线程的代码而言，我们总是以为代码的执行是从前往后的，依次执行的。这么说不能说完全不对，在单线程程序里，确实会这样执行；但是在多线程并发时，程序的执行就有可能出现乱序。用一句话可以总结为：在本线程内观察，操作都是有序的；如果在一个线程中观察另外一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行语义（WithIn Thread As-if-Serial Semantics）”,后半句是指“指令重排”现象和“工作内存和主内存同步延迟”现象。 Java提供了两个关键字volatile和synchronized来保证多线程之间操作的有序性,volatile关键字本身通过加入内存屏障来禁止指令的重排序，而synchronized关键字通过一个变量在同一时间只允许有一个线程对其进行加锁的规则来实现，在单线程程序中，不会发生“指令重排”和“工作内存和主内存同步延迟”现象，只在多线程程序中出现。 happens-before原则： Java内存模型中定义的两项操作之间的次序关系，如果说操作A先行发生于操作B，操作A产生的影响能被操作B观察到，“影响”包含了修改了内存中共享变量的值、发送了消息、调用了方法等。 下面是Java内存模型下一些”天然的“happens-before关系，这些happens-before关系无须任何同步器协助就已经存在，可以在编码中直接使用。如果两个操作之间的关系不在此列，并且无法从下列规则推导出来的话，它们就没有顺序性保障，虚拟机可以对它们进行随意地重排序。 程序次序规则(Pragram Order Rule)：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作。准确地说应该是控制流顺序而不是程序代码顺序，因为要考虑分支、循环结构。 管程锁定规则(Monitor Lock Rule)：一个unlock操作先行发生于后面对同一个锁的lock操作。这里必须强调的是同一个锁，而”后面“是指时间上的先后顺序。 volatile变量规则(Volatile Variable Rule)：对一个volatile变量的写操作先行发生于后面对这个变量的读取操作，这里的”后面“同样指时间上的先后顺序。 线程启动规则(Thread Start Rule)：Thread对象的start()方法先行发生于此线程的每一个动作。 线程终于规则(Thread Termination Rule)：线程中的所有操作都先行发生于对此线程的终止检测，我们可以通过Thread.join()方法结束，Thread.isAlive()的返回值等作段检测到线程已经终止执行。 线程中断规则(Thread Interruption Rule)：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过Thread.interrupted()方法检测是否有中断发生。 对象终结规则(Finalizer Rule)：一个对象初始化完成(构造方法执行完成)先行发生于它的finalize()方法的开始。 传递性(Transitivity)：如果操作A先行发生于操作B，操作B先行发生于操作C，那就可以得出操作A先行发生于操作C的结论。一个操作”时间上的先发生“不代表这个操作会是”先行发生“，那如果一个操作”先行发生“是否就能推导出这个操作必定是”时间上的先发生 “呢？也是不成立的，一个典型的例子就是指令重排序。所以时间上的先后顺序与happens-before原则之间基本没有什么关系，所以衡量并发安全问题一切必须以happens-before原则为准。 内存屏障 上面我们说了处理器会发生指令重排,现在来简单的看看常见处理器允许的重排规则,换言之就是处理器可以对那些指令进行顺序调整: 处理器 Load-Load Load-Store Store-Store Store-Load 数据依赖 x86 N N N Y N PowerPC Y Y Y Y N ia64 Y Y Y Y N 表格中的Y表示前后两个操作允许重排,N则表示不允许重排.与这些规则对应是的禁止重排的内存屏障. 注意:处理器和编译都会遵循数据依赖性,不会改变存在数据依赖关系的两个操作的顺序.所谓的数据依赖性就是如果两个操作访问同一个变量,且这两个操作中有一个是写操作,那么久可以称这两个操作存在数据依赖性.举个简单例子:code123456789a=100;//writeb=a;//read或者a=100;//writea=2000;//write或者a=b;//readb=12;//write 以上所示的,两个操作之间不能发生重排,这是处理器和编译所必须遵循的.当然这里指的是发生在单个处理器或单个线程中.在开始看一下表格之前,务必确保自己了解Store和Load指令的含义.简单来说,Store就是将处理器缓存中的数据刷新到内存中,而Load则是从内存拷贝数据到缓存当中. 屏障类型 指令示例 说明 LoadLoad Barriers Load1;LoadLoad;Load2 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作 StoreStore Barriers Store1;StoreStore;Store2 该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作 LoadStore Barriers Load1;LoadStore;Store2 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作 StoreLoad Barriers Store1;StoreLoad;Load1 该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作.它会使该屏障之前的所有内存访问指令(存储指令和访问指令)完成之后,才执行该屏障之后的内存访问指令 StoreLoad Barriers同时具备其他三个屏障的效果,因此也称之为全能屏障,是目前大多数处理器所支持的,但是相对其他屏障,该屏障的开销相对昂贵.在x86架构的处理器的指令集中,lock指令可以触发StoreLoad Barriers.现在我们综合重排规则和内存屏障类型来说明一下.比如x86架构的处理器中允许处理器对Store-Load操作进行重排,与之对应有StoreLoad Barriers禁止其重排. 重排序 重排序是指编译器和处理器为了优化程序性能而对指令序列进行重新排序的一种手段 数据依赖性 如果两个操作访问同一个变量，且这两个操作中有一个是写操作，此时这两个操作之间就存在数据依赖性。 as-if-serial语义 无论是处理器还是编译器,不管怎么重排都要保证(单线程)程序的执行结果不能被改变,这就是as-if-serial语义.正是因为as-if-serial的存在,我们在编写单线程程序时会觉得好像它就是按代码的顺序执行的,这让我们可以不必关心重排的影响. 顺序一致性数据竞争与数据一致性 java内存模型对数据竞争的定义： 在一个线程中写一个变量，在另一个线程读同一个变量，而且写和读没有通过同步来排序。 如果程序是正确同步的，程序的执行将具有顺序一致性————————即程序的执行结果与该程序在顺序一致性内存模型中的执行结果相同。 ## 顺序一致性内存模型 顺序一致性模型两大特性： 一个线程中的所有操作必须按照程序的顺序来执行 所有线程都只能看到一个单一的操作执行顺序。在顺序一致性内存模型中，每个操作都必须原子执行且立刻对所有线程可见。]]></content>
      <categories>
        <category>concurrent</category>
      </categories>
  </entry>
</search>
